{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_mps = torch.backends.mps.is_available()\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2index.pickle', 'rb') as handle:\n",
    "    word2index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_pickle('../data/abstracts_data/20k_abstracts/processed_train.pickle')\n",
    "test_df=pd.read_pickle('../data/abstracts_data/20k_abstracts/processed_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(label):\n",
    "    if label == \"RESULTS\":\n",
    "        return 0\n",
    "    elif label == \"METHODS\":\n",
    "        return 1\n",
    "    elif label == \"CONCLUSIONS\":\n",
    "        return 2\n",
    "    elif label == \"BACKGROUND\":\n",
    "        return 3\n",
    "    else: #positive\n",
    "        return 4\n",
    "\n",
    "seq_length = 194\n",
    "def encode_and_pad(tweet, length):\n",
    "    sos = [word2index[\"<SOS>\"]]\n",
    "    eos = [word2index[\"<EOS>\"]]\n",
    "    pad = [word2index[\"<PAD>\"]]\n",
    "\n",
    "    if len(tweet) < length - 2: # -2 for SOS and EOS\n",
    "        n_pads = length - 2 - len(tweet)\n",
    "        encoded = [word2index[w] for w in tweet]\n",
    "        return sos + encoded + eos + pad * n_pads \n",
    "    else: # tweet is longer than possible; truncating\n",
    "        encoded = [word2index[w] for w in tweet]\n",
    "        truncated = encoded[:length - 2]\n",
    "        return sos + truncated + eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(label, tokens) for label, tokens in zip(train_df['target'], train_df['text_tokens'])]\n",
    "test_set = [(label, tokens) for label, tokens in zip(test_df['target'], test_df['text_tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = [(encode_and_pad(tweet, seq_length), label_map(label)) for label, tweet in train_set]\n",
    "test_encoded = [(encode_and_pad(tweet, seq_length), label_map(label)) for label, tweet in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "#         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(_text)\n",
    "        offsets.append(_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   3,   4,  ...,   0,   0,   0],\n",
      "        [  1,  31,  32,  ...,   0,   0,   0],\n",
      "        [  1,  44,  45,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1, 395, 396,  ...,   0,   0,   0],\n",
      "        [  1, 432, 369,  ...,   0,   0,   0],\n",
      "        [  1, 434, 357,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_x = np.array([tweet for tweet, label in train_encoded])\n",
    "train_y = np.array([label for tweet, label in train_encoded])\n",
    "test_x = np.array([tweet for tweet, label in test_encoded])\n",
    "test_y = np.array([label for tweet, label in test_encoded])\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "\n",
    "# train_dl = DataLoader(train_ds, shuffle=False, batch_size=batch_size, drop_last=True, collate_fn=collate_batch)\n",
    "# test_dl = DataLoader(test_ds, shuffle=False, batch_size=batch_size, drop_last=True, collate_fn=collate_batch)\n",
    "\n",
    "train_dl = DataLoader(train_ds, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "for text, label in train_dl:\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Crypten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --user crypten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "import crypten\n",
    "import time\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot perform Gather operation using encrypted indices.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Elapsed:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time_elapsed))\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m time_elapsed\n\u001b[0;32m---> 33\u001b[0m time\u001b[38;5;241m=\u001b[39m\u001b[43mget_time_elapsed_crypten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [18], line 18\u001b[0m, in \u001b[0;36mget_time_elapsed_crypten\u001b[0;34m(device, test_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m             data_enc \u001b[38;5;241m=\u001b[39m crypten\u001b[38;5;241m.\u001b[39mcryptensor(data)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#             print(data_enc)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m             output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mprivate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_enc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m             output \u001b[38;5;241m=\u001b[39m output_enc\u001b[38;5;241m.\u001b[39mget_plain_text()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:50\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:532\u001b[0m, in \u001b[0;36mModule.__getattribute__.<locals>.forward_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, crypten\u001b[38;5;241m.\u001b[39mCrypTensor) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    529\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot input CrypTensors into unencrypted model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncrypt the model before feeding it CrypTensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m         )\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:714\u001b[0m, in \u001b[0;36mGraph.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# unpack iterable if possible\u001b[39;00m\n\u001b[1;32m    713\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[node_to_compute]\n\u001b[0;32m--> 714\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# we may get one output:\u001b[39;00m\n\u001b[1;32m    717\u001b[0m output_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_output_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:50\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:532\u001b[0m, in \u001b[0;36mModule.__getattribute__.<locals>.forward_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, crypten\u001b[38;5;241m.\u001b[39mCrypTensor) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    529\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot input CrypTensors into unencrypted model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncrypt the model before feeding it CrypTensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m         )\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/module.py:1642\u001b[0m, in \u001b[0;36mGather.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;66;03m# indices need to be a PyTorch tensor:\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m crypten\u001b[38;5;241m.\u001b[39mis_encrypted_tensor(indices):\n\u001b[0;32m-> 1642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot perform Gather operation using encrypted indices.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indices, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   1644\u001b[0m     indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(indices)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot perform Gather operation using encrypted indices."
     ]
    }
   ],
   "source": [
    "# # @mpc.run_multiprocess(world_size=2)\n",
    "# def get_time_elapsed_crypten(device, test_loader):\n",
    "#     plaintext_model = torch.load('./models/pt_text_classification_model_'+f'{torch.cuda.get_device_name(0)}.pth').to(device)\n",
    "#     dummy_input = text.to(device)\n",
    "\n",
    "#     private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "#     private_model.encrypt(src=0)\n",
    "#     private_model.eval()\n",
    "    \n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         t0 = time.perf_counter()\n",
    "#         for data, target in test_loader:\n",
    "#             target = target\n",
    "#             data_enc = crypten.cryptensor(data)\n",
    "# #             print(data_enc)\n",
    "#             output, hidden = private_model(data_enc)\n",
    "#             output = output_enc.get_plain_text()\n",
    "# #             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             preds = torch.argmax(F.softmax(output, dim=1),1)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#         time_elapsed = time.perf_counter() - t0\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "# #     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "# #         test_loss, correct, len(test_loader.dataset),\n",
    "# #         100. * correct / len(test_loader.dataset)))\n",
    "#     print('Time Elapsed:{}'.format(time_elapsed))\n",
    "#     return time_elapsed\n",
    "\n",
    "# time=get_time_elapsed_crypten(device, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 194])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CrypTensor class cannot be instantiated directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m data_enc \u001b[38;5;241m=\u001b[39m \u001b[43mcrypten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrypTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_enc\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m private_model(data_enc\u001b[38;5;241m.\u001b[39mflatten())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/cryptensor.py:203\u001b[0m, in \u001b[0;36mCrypTensor.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m CrypTensor:\n\u001b[0;32m--> 203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrypTensor class cannot be instantiated directly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: CrypTensor class cannot be instantiated directly."
     ]
    }
   ],
   "source": [
    "plaintext_model = torch.load('./models/pt_text_classification_model_'+f'{torch.cuda.get_device_name(0)}.pth').to('cpu')\n",
    "dummy_input = torch.zeros((1,194), dtype=torch.long)\n",
    "\n",
    "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "private_model.encrypt(src=0)\n",
    "private_model.eval()\n",
    "\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=1, drop_last=True)\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    t0 = time.perf_counter()\n",
    "    for data, target in test_dl:\n",
    "        target = target\n",
    "        print(data.shape)\n",
    "        data_enc = crypten.cryptensor(data)\n",
    "        print(data_enc.shape)\n",
    "        output, hidden = private_model(data_enc.flatten())\n",
    "        output = output_enc.get_plain_text()\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        preds = torch.argmax(F.softmax(output, dim=1),1)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    time_elapsed = time.perf_counter() - t0\n",
    "\n",
    "test_loss /= len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully encrypted: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Model successfully encrypted:\", private_model.encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', Graph encrypted module),\n",
       " ('embedding.weight', Parameter encrypted module),\n",
       " ('fc.weight', Parameter encrypted module),\n",
       " ('fc.bias', Parameter encrypted module),\n",
       " ('4', Gather encrypted module),\n",
       " ('5', Constant encrypted module),\n",
       " ('6', Gather encrypted module),\n",
       " ('output', Gemm encrypted module)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(private_model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([91942, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_model.embedding.state_dict()['weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModelv2(\n",
       "  (embedding): Embedding(91942, 64)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10.0",
   "language": "python",
   "name": "pytorch-1.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
