{"cells":[{"cell_type":"markdown","metadata":{"id":"N6ZDpd9XzFeN"},"source":["##### Copyright 2018 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"KUu4vOt5zI9d"},"outputs":[],"source":["# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="]},{"cell_type":"markdown","metadata":{"id":"edfbxDDh2AEs"},"source":["## Fashion MNIST with Keras and TPUs"]},{"cell_type":"markdown","metadata":{"id":"RNo1Vfghpa8j"},"source":["## Overview\n","\n","In this example, you can try out using tf.keras and Cloud TPUs to train a model on the fashion MNIST dataset. The model trains for 10 epochs on Cloud TPU and takes approximately 2 minutes to run.\n","\n","This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."]},{"cell_type":"markdown","metadata":{"id":"dgAHfQtuhddd"},"source":["## Learning objectives\n","\n","In this Colab, you will learn how to:\n","*   Code for a standard conv-net that has 3 layers with drop-out and batch normalization between each layer in Keras.\n","*   Create and compile the model under a distribution strategy in order ot use TPUs.\n","*   Run a prediction to see how well the model can predict fashion categories and output the result."]},{"cell_type":"markdown","metadata":{"id":"QrprJD-R-410"},"source":["## Instructions"]},{"cell_type":"markdown","metadata":{"id":"_I0RdnOSkNmi"},"source":["<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n","\n","1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n","1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "]},{"cell_type":"markdown","metadata":{"id":"5eEM-XOvURoU"},"source":["TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"]},{"cell_type":"markdown","metadata":{"id":"Lvo0t7XVIkWZ"},"source":["## Data, model, and training"]},{"cell_type":"markdown","metadata":{"id":"MICrRv8rmXVq"},"source":["Begin by downloading the fashion MNIST dataset using `tf.keras.datasets`, as shown below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zo-Yk6LFGfSf","executionInfo":{"status":"ok","timestamp":1667753778050,"user_tz":300,"elapsed":14144,"user":{"displayName":"","userId":""}},"outputId":"ec04a113-9d0c-48b2-8a52-8781a6b95a8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","import distutils\n","if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n","    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# add empty color dimension\n","x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)"]},{"cell_type":"markdown","metadata":{"id":"Hgc2FZKVMx15"},"source":["### Define the model\n","\n","The following example uses a standard conv-net that has 3 layers with drop-out and batch normalization between each layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7gMbs70GxA7"},"outputs":[],"source":["def create_model():\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n","  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n","  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  model.add(tf.keras.layers.Dropout(0.25))\n","\n","  model.add(tf.keras.layers.Flatten())\n","  model.add(tf.keras.layers.Dense(256))\n","  model.add(tf.keras.layers.Activation('elu'))\n","  model.add(tf.keras.layers.Dropout(0.5))\n","  model.add(tf.keras.layers.Dense(10))\n","  model.add(tf.keras.layers.Activation('softmax'))\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"xLeZATVaNAnE"},"source":["### Train on the TPU\n","\n","To begin training, construct the model on the TPU and then compile it."]},{"cell_type":"code","source":["from time import perf_counter\n","import gc"],"metadata":{"id":"GrdiU5Yi4YIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","\n","# This is the TPU initialization code that has to be at the beginning.\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","\n","strategy = tf.distribute.experimental.TPUStrategy(resolver)\n"],"metadata":{"id":"BuL5mukg5L7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWEYmd_hIWg8","executionInfo":{"status":"ok","timestamp":1667756162941,"user_tz":300,"elapsed":74839,"user":{"displayName":"","userId":""}},"outputId":"77fa6ddf-a983-4bb9-cc5c-a592fd5a2d6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","60/60 [==============================] - 8s 23ms/step - loss: 1.1725 - sparse_categorical_accuracy: 0.6792\n","Epoch 2/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.5366 - sparse_categorical_accuracy: 0.8181\n","Epoch 3/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.4389 - sparse_categorical_accuracy: 0.8498\n","Epoch 4/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8653\n","Epoch 5/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.3412 - sparse_categorical_accuracy: 0.8777\n","Epoch 6/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.8867\n","Epoch 7/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.8949\n","Epoch 8/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.9021\n","Epoch 9/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.2464 - sparse_categorical_accuracy: 0.9105\n","Epoch 10/40\n","60/60 [==============================] - 1s 24ms/step - loss: 0.2358 - sparse_categorical_accuracy: 0.9132\n","Epoch 11/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.9177\n","Epoch 12/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.2041 - sparse_categorical_accuracy: 0.9249\n","Epoch 13/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1944 - sparse_categorical_accuracy: 0.9278\n","Epoch 14/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1854 - sparse_categorical_accuracy: 0.9310\n","Epoch 15/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1731 - sparse_categorical_accuracy: 0.9348\n","Epoch 16/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9377\n","Epoch 17/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1587 - sparse_categorical_accuracy: 0.9389\n","Epoch 18/40\n","60/60 [==============================] - 1s 24ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9429\n","Epoch 19/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9456\n","Epoch 20/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1333 - sparse_categorical_accuracy: 0.9498\n","Epoch 21/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9511\n","Epoch 22/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9531\n","Epoch 23/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9560\n","Epoch 24/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9575\n","Epoch 25/40\n","60/60 [==============================] - 1s 24ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9613\n","Epoch 26/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9613\n","Epoch 27/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9631\n","Epoch 28/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9633\n","Epoch 29/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9655\n","Epoch 30/40\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0878 - sparse_categorical_accuracy: 0.9664\n","Epoch 31/40\n","60/60 [==============================] - 1s 24ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9681\n","Epoch 32/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9695\n","Epoch 33/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9689\n","Epoch 34/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9695\n","Epoch 35/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9729\n","Epoch 36/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9730\n","Epoch 37/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9755\n","Epoch 38/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9757\n","Epoch 39/40\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9744\n","Epoch 40/40\n","60/60 [==============================] - 8s 129ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.2857 - val_sparse_categorical_accuracy: 0.9268\n","perf counter 73.26443305600014\n"]},{"output_type":"execute_result","data":{"text/plain":["19395"]},"metadata":{},"execution_count":25}],"source":["with strategy.scope():\n","  model = create_model()\n","  model.compile(\n","      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n","      loss='sparse_categorical_crossentropy',\n","      metrics=['sparse_categorical_accuracy'])\n","\n","epochs = 20\n","batch_size = 256\n","start = perf_counter()\n","model.fit(\n","    x_train.astype(np.float32), y_train.astype(np.float32),\n","    epochs=epochs,\n","    # steps_per_epoch=60,\n","    batch_size=batch_size,\n","    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n","    validation_freq=epochs\n",")\n","print(f'perf counter {perf_counter()-start}')\n","model.save_weights('./fashion_mnist.h5', overwrite=True)\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"ESL6ltQTMm05"},"source":["### Check the results (inference)\n","\n","Now that you are done training, see how well the model can predict fashion categories!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaYPv_aKId2d"},"outputs":[],"source":["LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n","\n","\n","cpu_model = create_model()\n","cpu_model.load_weights('./fashion_mnist.h5')\n","\n","from matplotlib import pyplot\n","%matplotlib inline\n","\n","def plot_predictions(images, predictions):\n","  n = images.shape[0]\n","  nc = int(np.ceil(n / 4))\n","  f, axes = pyplot.subplots(nc, 4)\n","  for i in range(nc * 4):\n","    y = i // 4\n","    x = i % 4\n","    axes[x, y].axis('off')\n","    \n","    label = LABEL_NAMES[np.argmax(predictions[i])]\n","    confidence = np.max(predictions[i])\n","    if i > n:\n","      continue\n","    axes[x, y].imshow(images[i])\n","    axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n","\n","  pyplot.gcf().set_size_inches(8, 8)  \n","  plot_predictions(np.squeeze(x_test[:16]), cpu_model.predict(x_test[:16]))"]},{"cell_type":"markdown","metadata":{"id":"2a5cGsSTEBQD"},"source":["## What's next\n","\n","* Learn about [Cloud TPUs](https://cloud.google.com/tpu/docs) that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.\n","* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n","\n","On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured [deep learning VMs](https://cloud.google.com/deep-learning-vm/),  you will find [AutoML](https://cloud.google.com/automl/)*(beta)* for training custom models without writing code and [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/) which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.\n"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["N6ZDpd9XzFeN"],"provenance":[{"file_id":"https://github.com/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb","timestamp":1667756198789}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}