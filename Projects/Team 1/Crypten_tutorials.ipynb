{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Crypten\n",
        "Currently pip version of this framework is unstable due to some version dependency. It needs to be install from the source. [Issue link](https://github.com/facebookresearch/CrypTen/issues/391). \n",
        "\n",
        "Ignore this part if you have crypten already installed. This is exclusively for Google colab."
      ],
      "metadata": {
        "id": "v_U6fLIzG2Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/CrypTen.git\n",
        "%cd CrypTen\n",
        "# after this commit some version dependency is broken\n",
        "!git checkout efe8edad571be1c586d0d9cefc562d562d4e9aa1\n",
        "!python setup.py install --user"
      ],
      "metadata": {
        "id": "Z2D1RjhpqiNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check installed version"
      ],
      "metadata": {
        "id": "AJNFMMCNHCQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show crypten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFUSvPRf3eZv",
        "outputId": "47c7d457-0158-41b0-e5f5-514e11663d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: crypten\n",
            "Version: 0.4.0\n",
            "Summary: CrypTen: secure machine learning in PyTorch.\n",
            "Home-page: https://github.com/facebookresearch/CrypTen\n",
            "Author: Facebook AI Research\n",
            "Author-email: None\n",
            "License: MIT licensed, as found in the LICENSE file\n",
            "Location: /root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg\n",
            "Requires: torch, torchvision, omegaconf, onnx, pandas, pyyaml, tensorboard, future, scipy, sklearn\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fix existing bug\n",
        "[Issue link](https://github.com/facebookresearch/CrypTen/issues/438). Due to \"/config\" string in the setup.py of this framework, the crypten configs are not copied properly. You can either change \"/config\" to \"config\" manually or do the following."
      ],
      "metadata": {
        "id": "sVgeCTYPHSwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# current setup file doesn't copy the default.yaml correctly in the configs folder\n",
        "!cp configs/default.yaml /root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/configs/"
      ],
      "metadata": {
        "id": "aCiLt0Bu2voO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart the runtime\n",
        "You would need to restart the kernel runtime to load the newly installed crypten module. If you have restarted no need to run the prior cells. You can just start from here. "
      ],
      "metadata": {
        "id": "9B9BhxbLJYlI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCjqfb4gkDIE"
      },
      "source": [
        "# Tutorial 2: Inside CrypTensors\n",
        "This notebook is adapted from the original source tutorial [Tutorial_2_Inside_CrypTensors.ipynb](https://github.com/facebookresearch/CrypTen/blob/main/tutorials/Tutorial_2_Inside_CrypTensors.ipynb).\n",
        "\n",
        "Note: This tutorial is optional, and can be skipped without any loss of continuity to the following tutorials.\n",
        "\n",
        "\n",
        "In this tutorial, we will take a brief look at the internals of ```CrypTensors```. \n",
        "\n",
        "Using the `mpc` backend, a `CrypTensor` is a tensor encrypted using secure MPC protocols, called an `MPCTensor`. In order to support the mathematical operations required by the `MPCTensor`, CrypTen implements two kinds of secret-sharing protocols: arithmetic secret-sharing and binary secret-sharing. Arithmetic secret sharing forms the basis for most of the mathematical operations implemented by `MPCTensor`. Similarly, binary secret-sharing allows for the evaluation of logical expressions.\n",
        "\n",
        "In this tutorial, we'll first introduce the concept of a `CrypTensor` <i>ptype</i> (i.e. <i>private-type</i>), and show how to use it to obtain `MPCTensors` that use arithmetic and binary secret shares. We will also describe how each of these <i>ptypes</i> is used, and how they can be combined to implement desired functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Y0jxa3kDIG"
      },
      "outputs": [],
      "source": [
        "#import the libraries\n",
        "import crypten\n",
        "import torch\n",
        "\n",
        "# doesn't work in windows\n",
        "#initialize crypten\n",
        "crypten.init()\n",
        "#Disables OpenMP threads -- needed by @mpc.run_multiprocess which uses fork\n",
        "torch.set_num_threads(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_gIS4K21kDIH"
      },
      "source": [
        "## <i>ptype</i> in CrypTen\n",
        "CrypTen defines the `ptype` (for <i>private-type</i>) attribute of an `MPCTensor` to denote the kind of secret-sharing protocol used in the `CrypTensor`. The `ptype` is, in many ways, analogous to the `dtype` of PyTorch. The `ptype` may have two values: \n",
        "\n",
        "- `crypten.mpc.arithmetic` for `ArithmeticSharedTensors`</li>\n",
        "- `crypten.mpc.binary` for  `BinarySharedTensors`</li>\n",
        "\n",
        "We can use the `ptype` attribute to create a `CrypTensor` with the appropriate secret-sharing protocol. For example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCOkPMAXkDII",
        "outputId": "b8071f38-6ea6-4dc8-a5f6-42ad80a0290d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_enc internal type: ptype.arithmetic\n",
            "y_enc internal type: ptype.binary\n"
          ]
        }
      ],
      "source": [
        "#Constructing CrypTensors with ptype attribute\n",
        "\n",
        "#arithmetic secret-shared tensors\n",
        "x_enc = crypten.cryptensor([1.0, 2.0, 3.0], ptype=crypten.mpc.arithmetic)\n",
        "print(\"x_enc internal type:\", x_enc.ptype)\n",
        "\n",
        "#binary secret-shared tensors\n",
        "y = torch.tensor([1, 2, 1], dtype=torch.int32)\n",
        "y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n",
        "print(\"y_enc internal type:\", y_enc.ptype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79A-GuuckDII"
      },
      "source": [
        "### Arithmetic secret-sharing\n",
        "Let's look more closely at the `crypten.mpc.arithmetic` <i>ptype</i>. Most of the mathematical operations implemented by `CrypTensors` are implemented using arithmetic secret sharing. As such, `crypten.mpc.arithmetic` is the default <i>ptype</i> for newly generated `CrypTensors`. \n",
        "\n",
        "Let's begin by creating a new `CrypTensor` using `ptype=crypten.mpc.arithmetic` to enforce that the encryption is done via arithmetic secret sharing. We can print values of each share to confirm that values are being encrypted properly. \n",
        "\n",
        "To do so, we will need to create multiple parties to hold each share. We do this here using the `@mpc.run_multiprocess` function decorator, which we developed to execute crypten code from a single script (as we have in a Jupyter notebook). CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a `rank` variable to identify itself.\n",
        "\n",
        "Note that the sum of the two `_tensor` attributes below is equal to a scaled representation of the input. (Because MPC requires values to be integers, we scale input floats to a fixed-point encoding before encryption.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y2Z7FKBkDIJ",
        "outputId": "fa75cc37-75cd-450a-d338-8fa84cce0384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rank 0:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([ 5497951077848605038,  8173160353998178085, -3478346136588492155])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n",
            "\n",
            "Rank 1:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([-5497951077848539502, -8173160353998047013,  3478346136588688763])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.arithmetic\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import crypten.mpc as mpc\n",
        "import crypten.communicator as comm \n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def examine_arithmetic_shares():\n",
        "    x_enc = crypten.cryptensor([1, 2, 3], ptype=crypten.mpc.arithmetic)\n",
        "    \n",
        "    rank = comm.get().get_rank()\n",
        "    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n",
        "        \n",
        "x = examine_arithmetic_shares()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDqTzxkHkDIK"
      },
      "source": [
        "### Binary secret-sharing\n",
        "The second type of secret-sharing implemented in CrypTen is binary or XOR secret-sharing. This type of secret-sharing allows greater efficiency in evaluating logical expressions. \n",
        "\n",
        "Let's look more closely at the `crypten.mpc.binary` <i>ptype</i>. Most of the logical operations implemented by `CrypTensors` are implemented using arithmetic secret sharing. We typically use this type of secret-sharing when we want to evaluate binary operators (i.e. `^ & | >> <<`, etc.) or logical operations (like comparitors).\n",
        "\n",
        "Let's begin by creating a new `CrypTensor` using `ptype=crypten.mpc.binary` to enforce that the encryption is done via binary secret sharing. We can print values of each share to confirm that values are being encrypted properly, as we did for arithmetic secret-shares.\n",
        "\n",
        "(Note that an xor of the two `_tensor` attributes below is equal to an unscaled version of input.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baUSM3RbkDIK",
        "outputId": "86020812-f378-44c9-85b0-c8b5d7656262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rank 0:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([ 3865989190094285849, -2456286262483940891])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.binary\n",
            ")\n",
            "\n",
            "\n",
            "Rank 1:\n",
            " MPCTensor(\n",
            "\t_tensor=tensor([ 3865989190094285851, -2456286262483940890])\n",
            "\tplain_text=HIDDEN\n",
            "\tptype=ptype.binary\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def examine_binary_shares():\n",
        "    x_enc = crypten.cryptensor([2, 3], ptype=crypten.mpc.binary)\n",
        "    \n",
        "    rank = comm.get().get_rank()\n",
        "    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n",
        "        \n",
        "x = examine_binary_shares()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzZbpMDVkDIL"
      },
      "source": [
        "### Using Both Secret-sharing Protocols\n",
        "Quite often a mathematical function may need to use both additive and XOR secret sharing for efficient evaluation.  Functions that require conversions between sharing types include comparators (`>, >=, <, <=, ==, !=`) as well as functions derived from them (`abs, sign, relu`, etc.). For a full list of supported functions, please see the CrypTen documentation.\n",
        "\n",
        "CrypTen provides functionality that allows for the conversion of between <i>ptypes</i>. Conversion between <i>ptypes</i> can be done using the `.to()` function with a `crypten.ptype` input, or by calling the `.arithmetic()` and `.binary()` conversion functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDyjogXUkDIL",
        "outputId": "e2cf4725-de4d-4c81-8952-7ef0a02686e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to(crypten.binary):\n",
            "  ptype: ptype.binary\n",
            "  plaintext: tensor([1., 2., 3.])\n",
            "\n",
            "to(crypten.arithmetic):\n",
            "  ptype: ptype.arithmetic\n",
            "  plaintext: tensor([1., 2., 3.])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from crypten.mpc import MPCTensor\n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def examine_conversion():\n",
        "    x = torch.tensor([1, 2, 3])\n",
        "    rank = comm.get().get_rank()\n",
        "\n",
        "    # create an MPCTensor with arithmetic secret sharing\n",
        "    x_enc_arithmetic = MPCTensor(x, ptype=crypten.mpc.arithmetic)\n",
        "    \n",
        "    # To binary\n",
        "    x_enc_binary = x_enc_arithmetic.to(crypten.mpc.binary)\n",
        "    x_from_binary = x_enc_binary.get_plain_text()\n",
        "    \n",
        "    # print only once\n",
        "    crypten.print(\"to(crypten.binary):\")\n",
        "    crypten.print(f\"  ptype: {x_enc_binary.ptype}\\n  plaintext: {x_from_binary}\\n\")\n",
        "\n",
        "        \n",
        "    # To arithmetic\n",
        "    x_enc_arithmetic = x_enc_arithmetic.to(crypten.mpc.arithmetic)\n",
        "    x_from_arithmetic = x_enc_arithmetic.get_plain_text()\n",
        "    \n",
        "    # print only once\n",
        "    crypten.print(\"to(crypten.arithmetic):\")\n",
        "    crypten.print(f\"  ptype: {x_enc_arithmetic.ptype}\\n  plaintext: {x_from_arithmetic}\\n\")\n",
        "\n",
        "        \n",
        "z = examine_conversion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA1DPtxMkDIM"
      },
      "source": [
        "## Data Sources\n",
        "CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a `rank` variable to identify itself.\n",
        "\n",
        "If the process with rank `i` is the source of data `x`, then `x` gets encrypted with `i` as its source value (denoted as `src`). However, MPI protocols require that both processes to provide a tensor with the same size as their input. CrypTen ignores all data provided from non-source processes when encrypting.\n",
        "\n",
        "In the next example, we'll show how to use the `rank` and `src` values to encrypt tensors. Here, we will have each of 3 parties generate a value `x` which is equal to its own `rank` value. Within the loop, 3 encrypted tensors are created, each with a different source. When these tensors are decrypted, we can verify that the tensors are generated using the tensor provided by the source process.\n",
        "\n",
        "(Note that `crypten.cryptensor` uses rank 0 as the default source if none is provided.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj1aiC-EkDIN",
        "outputId": "6ea8d878-8ff2-4f0b-e7e9-3785ce45a1e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 0: 0\n",
            "Rank 1: 1\n",
            "Rank 2: 2\n",
            "Source 0: 0.0\n",
            "Source 1: 1.0\n",
            "Source 2: 2.0\n"
          ]
        }
      ],
      "source": [
        "@mpc.run_multiprocess(world_size=3)\n",
        "def examine_sources():\n",
        "    # Create a different tensor on each rank\n",
        "    rank = comm.get().get_rank()\n",
        "    x = torch.tensor(rank)\n",
        "    crypten.print(f\"Rank {rank}: {x}\", in_order=True)\n",
        "    \n",
        "    # \n",
        "    world_size = comm.get().get_world_size()\n",
        "    for i in range(world_size):\n",
        "        x_enc = crypten.cryptensor(x, src=i)\n",
        "        z = x_enc.get_plain_text()\n",
        "        \n",
        "        # Only print from one process to avoid duplicates\n",
        "        crypten.print(f\"Source {i}: {z}\")\n",
        "        \n",
        "x = examine_sources()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 4: Classification with Encrypted Neural Networks\n",
        "This tutorial is adapted from [Tutorial_4_Classification_with_Encrypted_Neural_Networks.ipynb](https://github.com/facebookresearch/CrypTen/blob/main/tutorials/Tutorial_4_Classification_with_Encrypted_Neural_Networks.ipynb).\n",
        "\n",
        "In this tutorial, we'll look at how we can achieve the <i>Model Hiding</i> application we discussed in the Introduction. That is, suppose say Alice has a trained model she wishes to keep private, and Bob has some data he wishes to classify while keeping it private. We will see how CrypTen allows Alice and Bob to coordinate and classify the data, while achieving their privacy requirements.\n",
        "\n",
        "To simulate this scenario, we will begin with Alice training a simple neural network on MNIST data. Then we'll see how Alice and Bob encrypt their network and data respectively, classify the encrypted data and finally decrypt the labels.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We first import the `torch` and `crypten` libraries, and initialize `crypten`. We will use a helper script `mnist_utils.py` to split the public MNIST data into Alice's portion and Bob's portion. "
      ],
      "metadata": {
        "id": "vpTYqb6q5Nsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CrypTen/tutorials/\n",
        "%run ./mnist_utils.py --option train_v_test"
      ],
      "metadata": {
        "id": "cUK1k0095jEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "f7e781e599764766a3a96b84b7d2082f",
            "8d8eb015a6b64325bad0ec7c95bd0a3f",
            "977862425c1f460783f9d6b81d479000",
            "58c064ecfb9e4a7a88e417bb751de9d3",
            "5c00bcd91a1d401a98167a7c34629628",
            "249a5d117bd84adfa3887a9e7f76dfec",
            "7dd52c10ea1d4d4dbcf333e4da0ab0a6",
            "62973f8b0aa8420dbd5e420d3a842410",
            "b12ac69ab5954b1ebd18bf3032325ca0",
            "eacc8a6df2104b2ea3a2140bd5f7ad2c",
            "c34b03c0acdb45b2820041d5db4d65ce",
            "a55c79c3c484413dbe5ea026facda72d",
            "28f445d1119b4f98bbf39c12546c3e96",
            "ccb1ef91ba3b42caa008cdbcebd73534",
            "5db39ee343864c099ab9346426d3e166",
            "9bc4aa4e8238476eaa9c42d3ea557095",
            "0facc4ff40974e6591d8052f50ac6043",
            "7ca392c767824e6ebcfa646a63c4149f",
            "6cf8320672e348f59a876657aa5daf5c",
            "87c0a023ace4420495eceab802f134ec",
            "5451cde9942e4a45a5af6ebe367438f2",
            "29b50e2140ac473c846c5400e65553bf",
            "8be55a40b8bf41ae898aba2d3008fc15",
            "3e4a563754d34666b2e6c2f1bfe4f670",
            "872a9157b5834b84a1370a43237eafa9",
            "6f0b033be3434539857c67b630bd150e",
            "4c4ddd3b9dd94daa9e0ae7c71d273ba3",
            "5c56ccbf77b14f62a300d547d3723262",
            "2f15fd31e81041a59a101d3ba46c3bbf",
            "32f2ecb6f48a40dabac28df9df5a2bb1",
            "b3e5bacb00c94e6191a93024b1418514",
            "6046ef7e47ff44019209c32a053e133f",
            "58b370187747426691c187636a146ff0",
            "78413ffdc5514268969616824107666d",
            "4cbf513d83214056a57a43609846dcfa",
            "887b463312714bc889e00837b7929626",
            "6356068139fe475895f1d92418da8f43",
            "2dc0b263440c4ec189e4886fba11ebdc",
            "8aca6e0d6b0c4b159e56882cffc19ba7",
            "755327f50fc34df18ac846fd8c0ce694",
            "5d5a179a0a9f4dca8346d2b51e24dcb3",
            "73433b3ff00d45be88614bc2f8366215",
            "95df5428e135474d84900ee02f2b86a5",
            "8cf3d9ffe87d4892aefa8be00edfa424"
          ]
        },
        "outputId": "858025a5-48dd-4a3d-dbef-fd6b2694465a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CrypTen/tutorials\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7e781e599764766a3a96b84b7d2082f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a55c79c3c484413dbe5ea026facda72d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8be55a40b8bf41ae898aba2d3008fc15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78413ffdc5514268969616824107666d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will define the structure of Alice's network as a class. Even though Alice has a pre-trained model, the CrypTen will require this structure as input."
      ],
      "metadata": {
        "id": "_nssC3TEKsoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Alice's network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AliceNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AliceNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "    \n",
        "crypten.common.serial.register_safe_class(AliceNet)"
      ],
      "metadata": {
        "id": "4M4FR3wh7K-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also define a helper routine `compute_accuracy` to make it easy to compute the accuracy of the output we get."
      ],
      "metadata": {
        "id": "qGdnx_MBMTJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(output, labels):\n",
        "    pred = output.argmax(1)\n",
        "    correct = pred.eq(labels)\n",
        "    correct_count = correct.sum(0, keepdim=True).float()\n",
        "    accuracy = correct_count.mul_(100.0 / output.size(0))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_nbz6SRfMUTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encrypting a Pre-trained Model\n",
        "\n",
        "Assume that Alice has a pre-trained network ready to classify data. Let's see how we can use CrypTen to encrypt this network, so it can be used to classify data without revealing its parameters. We'll use the pre-trained model in `models/tutorial4_alice_model.pth` in this tutorial. As in Tutorial 3, we will assume Alice is using the rank 0 process, while Bob is using the rank 1 process. "
      ],
      "metadata": {
        "id": "4YRsui82KlP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source argument values for Alice and Bob\n",
        "ALICE = 0\n",
        "BOB = 1"
      ],
      "metadata": {
        "id": "BF3rQBF95n1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In CrypTen, encrypting PyTorch network is straightforward: we load a PyTorch model from file to the appropriate source, convert it to a CrypTen model and then encrypt it. Let us understand each of these steps.\n",
        "\n",
        "As we did with CrypTensors in Tutorial 3, we will use CrypTen's load functionality (i.e., `crypten.load`) to read a model from file to a particular source. The source is indicated by the keyword argument `src`. As in Tutorial 3, this src argument tells us the rank of the party we want to load the model to (and later, encrypt the model from). In addition, here we also need to provide a dummy model to tell CrypTen the model's structure. The dummy model is indicated by the keyword argument `dummy_model`. Note that unlike loading a tensor, the result from `crypten.load` is not encrypted. Instead, only the `src` party's model is populated from the file.\n",
        "\n",
        "Once the model is loaded, we call the function `from_pytorch`: this function sets up a CrypTen network from the PyTorch network. It takes the plaintext network as input as well as dummy input. The dummy input must be a `torch` tensor of the same shape as a potential input to the network, however the values inside the tensor do not matter.  \n",
        "\n",
        "Finally, we call `encrypt` on the CrypTen network to encrypt its parameters. Once we call the `encrypt` function, the models `encrypted` property will verify that the model parameters have been encrypted. (Encrypted CrypTen networks can also be decrypted using the `decrypt` function)."
      ],
      "metadata": {
        "id": "ll-mtk_HL_lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model to Alice\n",
        "dummy_model = AliceNet()\n",
        "plaintext_model = torch.load('models/tutorial4_alice_model.pth')\n",
        "\n",
        "print(plaintext_model)\n",
        "\n",
        "# Encrypt the model from Alice:    \n",
        "\n",
        "# 1. Create a dummy input with the same shape as the model input\n",
        "dummy_input = torch.empty((1, 784))\n",
        "\n",
        "# 2. Construct a CrypTen network with the trained model and dummy_input\n",
        "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
        "\n",
        "# 3. Encrypt the CrypTen network with src=ALICE\n",
        "private_model.encrypt(src=ALICE)\n",
        "\n",
        "#Check that model is encrypted:\n",
        "print(\"Model successfully encrypted:\", private_model.encrypted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oIjsi-cMCOn",
        "outputId": "9e9a41d5-04ea-4bbb-837c-044b3ca31d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AliceNet(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "Model successfully encrypted: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)\n",
            "  param = torch.from_numpy(numpy_helper.to_array(node))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying Encrypted Data with Encrypted Model\n",
        "\n",
        "We can now use Alice's encrypted network to classify Bob's data. For this, we need to encrypt Bob's data as well, as we did in Tutorial 3 (recall that Bob has the rank 1 process). Once Alice's network and Bob's data are both encrypted, CrypTen inference is performed with essentially identical steps as in PyTorch. "
      ],
      "metadata": {
        "id": "rk-lK0EBMjdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import crypten.mpc as mpc\n",
        "import crypten.communicator as comm\n",
        "\n",
        "labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
        "count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
        "\n",
        "@mpc.run_multiprocess(world_size=2)\n",
        "def encrypt_model_and_data():\n",
        "    # Load pre-trained model to Alice\n",
        "    model = crypten.load_from_party('models/tutorial4_alice_model.pth', src=ALICE)\n",
        "    \n",
        "    # Encrypt model from Alice \n",
        "    dummy_input = torch.empty((1, 784))\n",
        "    private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
        "    private_model.encrypt(src=ALICE)\n",
        "    \n",
        "    # Load data to Bob\n",
        "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
        "    data_enc2 = data_enc[:count]\n",
        "    data_flatten = data_enc2.flatten(start_dim=1)\n",
        "\n",
        "    # Classify the encrypted data\n",
        "    private_model.eval()\n",
        "    output_enc = private_model(data_flatten)\n",
        "    \n",
        "    # Compute the accuracy\n",
        "    output = output_enc.get_plain_text()\n",
        "    accuracy = compute_accuracy(output, labels[:count])\n",
        "    crypten.print(\"\\tAccuracy: {0:.4f}\".format(accuracy.item()))\n",
        "    \n",
        "encrypt_model_and_data()"
      ],
      "metadata": {
        "id": "hoszlSkYMlCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validating Encrypted Classification\n",
        "\n",
        "Finally, we will verify that CrypTen classification results in encrypted output, and that this output can be decrypted into meaningful labels. \n",
        "\n",
        "To see this, in this tutorial, we will just check whether the result is an encrypted tensor; in the next tutorial, we will look into the values of tensor and confirm the encryption. We will also decrypt the result. As we discussed before, Alice and Bob both have access to the decrypted output of the model, and can both use this to obtain the labels. "
      ],
      "metadata": {
        "id": "J8HbLMH-M5Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@mpc.run_multiprocess(world_size=2)\n",
        "def encrypt_model_and_data():\n",
        "    # Load pre-trained model to Alice\n",
        "    plaintext_model = crypten.load_from_party('models/tutorial4_alice_model.pth', src=ALICE)\n",
        "    \n",
        "    # Encrypt model from Alice \n",
        "    dummy_input = torch.empty((1, 784))\n",
        "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
        "    private_model.encrypt(src=ALICE)\n",
        "    \n",
        "    # Load data to Bob\n",
        "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
        "    data_enc2 = data_enc[:count]\n",
        "    data_flatten = data_enc2.flatten(start_dim=1)\n",
        "\n",
        "    # Classify the encrypted data\n",
        "    private_model.eval()\n",
        "    output_enc = private_model(data_flatten)\n",
        "    \n",
        "    # Verify the results are encrypted: \n",
        "    crypten.print(\"Output tensor encrypted:\", crypten.is_encrypted_tensor(output_enc)) \n",
        "\n",
        "    # Decrypting the result\n",
        "    output = output_enc.get_plain_text()\n",
        "\n",
        "    # Obtaining the labels\n",
        "    pred = output.argmax(dim=1)\n",
        "    crypten.print(\"Decrypted labels:\\n\", pred)\n",
        "    \n",
        "encrypt_model_and_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVmfpalYM7jA",
        "outputId": "dd5fcce2-2625-4ab4-f53e-63a01e137960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-16:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/mpc/context.py\", line 30, in _launch\n",
            "    return_value = func(*func_args, **func_kwargs)\n",
            "  File \"<ipython-input-18-247e6e674f50>\", line 8, in encrypt_model_and_data\n",
            "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/nn/onnx_converter.py\", line 47, in from_pytorch\n",
            "    crypten_model = from_onnx(f)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/nn/onnx_converter.py\", line 36, in from_onnx\n",
            "    return _to_crypten(onnx_model)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/nn/onnx_converter.py\", line 172, in _to_crypten\n",
            "    crypten_class = _get_operator_class(node.op_type, attributes)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/nn/onnx_converter.py\", line 248, in _get_operator_class\n",
            "    raise ValueError(f\"CrypTen does not support ONNX op {node_op_type}.\")\n",
            "ValueError: CrypTen does not support ONNX op Identity.\n",
            "Process Process-15:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/mpc/context.py\", line 30, in _launch\n",
            "    return_value = func(*func_args, **func_kwargs)\n",
            "  File \"<ipython-input-18-247e6e674f50>\", line 12, in encrypt_model_and_data\n",
            "    data_enc = crypten.load_from_party('/tmp/bob_test.pth', src=BOB)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/__init__.py\", line 353, in load_from_party\n",
            "    result = comm.get().broadcast_obj(None, src)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/communicator/communicator.py\", line 234, in logging_wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/root/.local/lib/python3.8/site-packages/crypten-0.4.0-py3.8.egg/crypten/communicator/distributed_communicator.py\", line 318, in broadcast_obj\n",
            "    dist.broadcast(size, src, group=group)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py\", line 1201, in broadcast\n",
            "    work.wait()\n",
            "RuntimeError: [../third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.28.0.12]:1441\n",
            "ERROR:root:One of the parties failed. Check past logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 7: Training an Encrypted Neural Network\n",
        "Source adapted from [Tutorial_7_Training_an_Encrypted_Neural_Network.ipynb](https://github.com/facebookresearch/CrypTen/blob/main/tutorials/Tutorial_7_Training_an_Encrypted_Neural_Network.ipynb)\n",
        "\n",
        "In this tutorial, we will walk through an example of how we can train a neural network with CrypTen. This is particularly relevant for the <i>Feature Aggregation</i>, <i>Data Labeling</i> and <i>Data Augmentation</i> use cases. We will focus on the usual two-party setting and show how we can train an accurate neural network for digit classification on the MNIST data.\n",
        "\n",
        "For concreteness, this tutorial will step through the <i>Feature Aggregation</i> use cases: Alice and Bob each have part of the features of the data set, and wish to train a neural network on their combined data, while keeping their data private. "
      ],
      "metadata": {
        "id": "J-nfWDyQToVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "As usual, we'll begin by importing and initializing the `crypten` and `torch` libraries.  \n",
        "\n",
        "We will use the MNIST dataset to demonstrate how Alice and Bob can learn without revealing protected information. For reference, the feature size of each example in the MNIST data is `28 x 28`. Let's assume Alice has the first `28 x 20` features and Bob has last `28 x 8` features. One way to think of this split is that Alice has the (roughly) top 2/3rds of each image, while Bob has the bottom 1/3rd of each image. We'll again use our helper script `mnist_utils.py` that downloads the publicly available MNIST data, and splits the data as required.\n",
        "\n",
        "For simplicity, we will restrict our problem to binary classification: we'll simply learn how to distinguish between 0 and non-zero digits. For speed of execution in the notebook, we will only create a dataset of a 100 examples."
      ],
      "metadata": {
        "id": "J2YBNiVyPBx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run ./mnist_utils.py --option features --reduced 100 --binary"
      ],
      "metadata": {
        "id": "pE4eXrG8SjOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll define the network architecture below, and then describe how to train it on encrypted data in the next section. "
      ],
      "metadata": {
        "id": "i3LOXWeFSm1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Define an example network\n",
        "class ExampleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 12 * 12, 100)\n",
        "        self.fc2 = nn.Linear(100, 2) # For binary classification, final layer needs only 2 outputs\n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 16 * 12 * 12)\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "crypten.common.serial.register_safe_class(ExampleNet)"
      ],
      "metadata": {
        "id": "bMYjN0TbSleP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encrypted Training\n",
        "\n",
        "After all the material we've covered in earlier tutorials, we only need to know a few additional items for encrypted training. We'll first discuss how the training loop in CrypTen differs from PyTorch. Then, we'll go through a complete example to illustrate training on encrypted data from end-to-end."
      ],
      "metadata": {
        "id": "2zkMRUrnTi1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### How does CrypTen training differ from PyTorch training?\n",
        "\n",
        "There are two main ways implementing a CrypTen training loop differs from a PyTorch training loop. We'll describe these items first, and then illustrate them with small examples below.\n",
        "\n",
        "<i>(1) Use one-hot encoding</i>: CrypTen training requires all labels to use one-hot encoding. This means that when using standard datasets such as MNIST, we need to modify the labels to use one-hot encoding.\n",
        "\n",
        "<i>(2) Directly update parameters</i>: CrypTen does not use the PyTorch optimizers. Instead, CrypTen implements encrypted SGD by implementing its own `backward` function, followed by directly updating the parameters. As we will see below, using SGD in CrypTen is very similar to using the PyTorch optimizers.\n",
        "\n",
        "We now show some small examples to illustrate these differences. As before, we will assume Alice has the rank 0 process and Bob has the rank 1 process."
      ],
      "metadata": {
        "id": "3IGDl89-SqhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source argument values for Alice and Bob\n",
        "ALICE = 0\n",
        "BOB = 1\n",
        "\n",
        "# Load Alice's data \n",
        "data_alice_enc = crypten.load_from_party('/tmp/alice_train.pth', src=ALICE)"
      ],
      "metadata": {
        "id": "tJvv9uvN8yzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll now set up the data for our small example below\n",
        "# For illustration purposes, we will create toy data\n",
        "# and encrypt all of it from source ALICE\n",
        "x_small = torch.rand(100, 1, 28, 28)\n",
        "y_small = torch.randint(1, (100,))\n",
        "\n",
        "# Transform labels into one-hot encoding\n",
        "label_eye = torch.eye(2)\n",
        "y_one_hot = label_eye[y_small]\n",
        "\n",
        "# Transform all data to CrypTensors\n",
        "x_train = crypten.cryptensor(x_small, src=ALICE)\n",
        "y_train = crypten.cryptensor(y_one_hot)\n",
        "\n",
        "# Instantiate and encrypt a CrypTen model\n",
        "model_plaintext = ExampleNet()\n",
        "dummy_input = torch.empty(1, 1, 28, 28)\n",
        "model = crypten.nn.from_pytorch(model_plaintext, dummy_input)\n",
        "model.encrypt()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL5UmspH82ra",
        "outputId": "3204dc84-4ffd-45d8-aa35-701fc77725fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph encrypted module"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Stochastic Gradient Descent in CrypTen\n",
        "\n",
        "model.train() # Change to training mode\n",
        "loss = crypten.nn.MSELoss() # Choose loss functions\n",
        "\n",
        "# Set parameters: learning rate, num_epochs\n",
        "learning_rate = 0.001\n",
        "num_epochs = 2\n",
        "\n",
        "# Train the model: SGD on encrypted data\n",
        "for i in range(num_epochs):\n",
        "\n",
        "    # forward pass\n",
        "    output = model(x_train)\n",
        "    loss_value = loss(output, y_train)\n",
        "    \n",
        "    # set gradients to zero\n",
        "    model.zero_grad()\n",
        "\n",
        "    # perform backward pass\n",
        "    loss_value.backward()\n",
        "\n",
        "    # update parameters\n",
        "    model.update_parameters(learning_rate) \n",
        "    \n",
        "    # examine the loss after each epoch\n",
        "    print(\"Epoch: {0:d} Loss: {1:.4f}\".format(i, loss_value.get_plain_text()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ungd2-SY9RYt",
        "outputId": "48d0bc6b-637c-4c31-e730-818022da902c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 0.5165\n",
            "Epoch: 1 Loss: 0.4839\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7e781e599764766a3a96b84b7d2082f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d8eb015a6b64325bad0ec7c95bd0a3f",
              "IPY_MODEL_977862425c1f460783f9d6b81d479000",
              "IPY_MODEL_58c064ecfb9e4a7a88e417bb751de9d3"
            ],
            "layout": "IPY_MODEL_5c00bcd91a1d401a98167a7c34629628"
          }
        },
        "8d8eb015a6b64325bad0ec7c95bd0a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249a5d117bd84adfa3887a9e7f76dfec",
            "placeholder": "",
            "style": "IPY_MODEL_7dd52c10ea1d4d4dbcf333e4da0ab0a6",
            "value": "100%"
          }
        },
        "977862425c1f460783f9d6b81d479000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62973f8b0aa8420dbd5e420d3a842410",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b12ac69ab5954b1ebd18bf3032325ca0",
            "value": 9912422
          }
        },
        "58c064ecfb9e4a7a88e417bb751de9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacc8a6df2104b2ea3a2140bd5f7ad2c",
            "placeholder": "",
            "style": "IPY_MODEL_c34b03c0acdb45b2820041d5db4d65ce",
            "value": " 9912422/9912422 [00:00&lt;00:00, 27471386.86it/s]"
          }
        },
        "5c00bcd91a1d401a98167a7c34629628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249a5d117bd84adfa3887a9e7f76dfec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd52c10ea1d4d4dbcf333e4da0ab0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62973f8b0aa8420dbd5e420d3a842410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12ac69ab5954b1ebd18bf3032325ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eacc8a6df2104b2ea3a2140bd5f7ad2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34b03c0acdb45b2820041d5db4d65ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a55c79c3c484413dbe5ea026facda72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28f445d1119b4f98bbf39c12546c3e96",
              "IPY_MODEL_ccb1ef91ba3b42caa008cdbcebd73534",
              "IPY_MODEL_5db39ee343864c099ab9346426d3e166"
            ],
            "layout": "IPY_MODEL_9bc4aa4e8238476eaa9c42d3ea557095"
          }
        },
        "28f445d1119b4f98bbf39c12546c3e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0facc4ff40974e6591d8052f50ac6043",
            "placeholder": "",
            "style": "IPY_MODEL_7ca392c767824e6ebcfa646a63c4149f",
            "value": "100%"
          }
        },
        "ccb1ef91ba3b42caa008cdbcebd73534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf8320672e348f59a876657aa5daf5c",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87c0a023ace4420495eceab802f134ec",
            "value": 28881
          }
        },
        "5db39ee343864c099ab9346426d3e166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5451cde9942e4a45a5af6ebe367438f2",
            "placeholder": "",
            "style": "IPY_MODEL_29b50e2140ac473c846c5400e65553bf",
            "value": " 28881/28881 [00:00&lt;00:00, 701865.65it/s]"
          }
        },
        "9bc4aa4e8238476eaa9c42d3ea557095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0facc4ff40974e6591d8052f50ac6043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca392c767824e6ebcfa646a63c4149f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cf8320672e348f59a876657aa5daf5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c0a023ace4420495eceab802f134ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5451cde9942e4a45a5af6ebe367438f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b50e2140ac473c846c5400e65553bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be55a40b8bf41ae898aba2d3008fc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e4a563754d34666b2e6c2f1bfe4f670",
              "IPY_MODEL_872a9157b5834b84a1370a43237eafa9",
              "IPY_MODEL_6f0b033be3434539857c67b630bd150e"
            ],
            "layout": "IPY_MODEL_4c4ddd3b9dd94daa9e0ae7c71d273ba3"
          }
        },
        "3e4a563754d34666b2e6c2f1bfe4f670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c56ccbf77b14f62a300d547d3723262",
            "placeholder": "",
            "style": "IPY_MODEL_2f15fd31e81041a59a101d3ba46c3bbf",
            "value": "100%"
          }
        },
        "872a9157b5834b84a1370a43237eafa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f2ecb6f48a40dabac28df9df5a2bb1",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3e5bacb00c94e6191a93024b1418514",
            "value": 1648877
          }
        },
        "6f0b033be3434539857c67b630bd150e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6046ef7e47ff44019209c32a053e133f",
            "placeholder": "",
            "style": "IPY_MODEL_58b370187747426691c187636a146ff0",
            "value": " 1648877/1648877 [00:00&lt;00:00, 11578207.32it/s]"
          }
        },
        "4c4ddd3b9dd94daa9e0ae7c71d273ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c56ccbf77b14f62a300d547d3723262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f15fd31e81041a59a101d3ba46c3bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f2ecb6f48a40dabac28df9df5a2bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e5bacb00c94e6191a93024b1418514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6046ef7e47ff44019209c32a053e133f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b370187747426691c187636a146ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78413ffdc5514268969616824107666d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cbf513d83214056a57a43609846dcfa",
              "IPY_MODEL_887b463312714bc889e00837b7929626",
              "IPY_MODEL_6356068139fe475895f1d92418da8f43"
            ],
            "layout": "IPY_MODEL_2dc0b263440c4ec189e4886fba11ebdc"
          }
        },
        "4cbf513d83214056a57a43609846dcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aca6e0d6b0c4b159e56882cffc19ba7",
            "placeholder": "",
            "style": "IPY_MODEL_755327f50fc34df18ac846fd8c0ce694",
            "value": "100%"
          }
        },
        "887b463312714bc889e00837b7929626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5a179a0a9f4dca8346d2b51e24dcb3",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73433b3ff00d45be88614bc2f8366215",
            "value": 4542
          }
        },
        "6356068139fe475895f1d92418da8f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95df5428e135474d84900ee02f2b86a5",
            "placeholder": "",
            "style": "IPY_MODEL_8cf3d9ffe87d4892aefa8be00edfa424",
            "value": " 4542/4542 [00:00&lt;00:00, 114542.80it/s]"
          }
        },
        "2dc0b263440c4ec189e4886fba11ebdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aca6e0d6b0c4b159e56882cffc19ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755327f50fc34df18ac846fd8c0ce694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5a179a0a9f4dca8346d2b51e24dcb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73433b3ff00d45be88614bc2f8366215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95df5428e135474d84900ee02f2b86a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf3d9ffe87d4892aefa8be00edfa424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}