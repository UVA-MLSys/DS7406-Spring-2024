/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)
  param = torch.from_numpy(numpy_helper.to_array(node))
NVIDIA GeForce RTX 2080 Ti
Using cuda backend.
Shape: Train data torch.Size([60000, 28, 28]), test data torch.Size([10000, 28, 28]).
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.310747
Train Epoch: 1 [6400/60000 (11%)]	Loss: 0.829704
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.243101
Train Epoch: 1 [19200/60000 (32%)]	Loss: 0.560366
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.385813
Train Epoch: 1 [32000/60000 (53%)]	Loss: 0.415710
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.364651
Train Epoch: 1 [44800/60000 (75%)]	Loss: 0.303712
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.081622
Train Epoch: 1 [57600/60000 (96%)]	Loss: 0.153592

Train set: Average loss: 436.7345, Elapsed time 7.6333 seconds.

Test set: Average loss: 0.0002, Accuracy: 94.4500%, Elapsed time 1.2492 seconds.
Train time (seconds): total 7.63329, mean 7.63329.
 Test time (seconds): total 1.24924, mean 1.24924.
Traceback (most recent call last):
  File "/u/mi3se/Git/Team1/benchmark.py", line 288, in <module>
    test_loss, elapsed_time, accuracy = test_encrypted(model_enc, device, test_loader)
  File "/u/mi3se/Git/Team1/benchmark.py", line 270, in test_encrypted
    output = model(data)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 50, in __call__
    return self.forward(*args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 532, in forward_function
    return object.__getattribute__(self, name)(*tuple(args), **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 714, in forward
    output = module(input)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 50, in __call__
    return self.forward(*args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 532, in forward_function
    return object.__getattribute__(self, name)(*tuple(args), **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/nn/module.py", line 1967, in forward
    x = func(*args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/cryptensor.py", line 338, in autograd_forward
    return self.__getattribute__(name)(*args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/mpc.py", line 339, in binary_wrapper_function
    result._tensor = getattr(result._tensor, name)(value, *args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/primitives/arithmetic.py", line 494, in conv2d
    return self._arithmetic_function(kernel, "conv2d", **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/primitives/arithmetic.py", line 384, in _arithmetic_function
    getattr(protocol, op)(result, y, *args, **kwargs).share.data
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/primitives/beaver.py", line 102, in conv2d
    return __beaver_protocol("conv2d", x, y, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/primitives/beaver.py", line 51, in __beaver_protocol
    a, b, c = provider.generate_additive_triple(
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/mpc/provider/tfp_provider.py", line 25, in generate_additive_triple
    c = getattr(torch, op)(a, b, *args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/cuda/cuda_tensor.py", line 99, in __torch_function__
    return HANDLED_FUNCTIONS[func](*args, **kwargs)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/cuda/cuda_tensor.py", line 297, in conv2d
    return CUDALongTensor.__patched_conv_ops(
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/cuda/cuda_tensor.py", line 223, in __patched_conv_ops
    return CUDALongTensor.__decode_as_int64(z_encoded, nb)
  File "/u/mi3se/.local/lib/python3.9/site-packages/crypten-0.4.0-py3.9.egg/crypten/cuda/cuda_tensor.py", line 187, in __decode_as_int64
    return CUDALongTensor(result.sum(0))
RuntimeError: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 10.76 GiB total capacity; 9.26 GiB already allocated; 53.44 MiB free; 9.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
