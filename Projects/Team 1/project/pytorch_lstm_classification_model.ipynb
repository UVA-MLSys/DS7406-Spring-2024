{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2index.pickle', 'rb') as handle:\n",
    "    word2index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " 'investigate': 3,\n",
       " 'efficacy': 4,\n",
       " '6': 5,\n",
       " 'weeks': 6,\n",
       " 'daily': 7,\n",
       " 'lowdose': 8,\n",
       " 'oral': 9,\n",
       " 'prednisolone': 10,\n",
       " 'improving': 11,\n",
       " 'pain': 12,\n",
       " 'mobility': 13,\n",
       " 'systemic': 14,\n",
       " 'lowgrade': 15,\n",
       " 'inflammation': 16,\n",
       " 'short': 17,\n",
       " 'term': 18,\n",
       " 'whether': 19,\n",
       " 'effect': 20,\n",
       " 'would': 21,\n",
       " 'sustained': 22,\n",
       " '12': 23,\n",
       " 'older': 24,\n",
       " 'adults': 25,\n",
       " 'moderate': 26,\n",
       " 'severe': 27,\n",
       " 'knee': 28,\n",
       " 'osteoarthritis': 29,\n",
       " 'oa': 30,\n",
       " 'total': 31,\n",
       " '125': 32,\n",
       " 'patients': 33,\n",
       " 'primary': 34,\n",
       " 'randomized': 35,\n",
       " '11': 36,\n",
       " '63': 37,\n",
       " 'received': 38,\n",
       " '75': 39,\n",
       " 'mg': 40,\n",
       " 'day': 41,\n",
       " '62': 42,\n",
       " 'placebo': 43,\n",
       " 'outcome': 44,\n",
       " 'measures': 45,\n",
       " 'included': 46,\n",
       " 'reduction': 47,\n",
       " 'improvement': 48,\n",
       " 'function': 49,\n",
       " 'scores': 50,\n",
       " 'markers': 51,\n",
       " 'assessed': 52,\n",
       " 'using': 53,\n",
       " 'visual': 54,\n",
       " 'analog': 55,\n",
       " 'scale': 56,\n",
       " '0100': 57,\n",
       " 'mm': 58,\n",
       " 'secondary': 59,\n",
       " 'western': 60,\n",
       " 'ontario': 61,\n",
       " 'mcmaster': 62,\n",
       " 'universities': 63,\n",
       " 'inde': 64,\n",
       " 'patient': 65,\n",
       " 'global': 66,\n",
       " 'assessment': 67,\n",
       " 'pga': 68,\n",
       " 'severity': 69,\n",
       " '6min': 70,\n",
       " 'walk': 71,\n",
       " 'distance': 72,\n",
       " '6mwd': 73,\n",
       " 'serum': 74,\n",
       " 'levels': 75,\n",
       " 'interleukin': 76,\n",
       " '1': 77,\n",
       " 'il1': 78,\n",
       " 'il6': 79,\n",
       " 'tumor': 80,\n",
       " 'necrosis': 81,\n",
       " 'factor': 82,\n",
       " 'tnf': 83,\n",
       " 'highsensitivity': 84,\n",
       " 'creactive': 85,\n",
       " 'protein': 86,\n",
       " 'hscrp': 87,\n",
       " 'measured': 88,\n",
       " 'clinically': 89,\n",
       " 'relevant': 90,\n",
       " 'intervention': 91,\n",
       " 'group': 92,\n",
       " 'compared': 93,\n",
       " 'physical': 94,\n",
       " 'mean': 95,\n",
       " 'difference': 96,\n",
       " 'treatment': 97,\n",
       " 'arms': 98,\n",
       " '95': 99,\n",
       " 'ci': 100,\n",
       " '109': 101,\n",
       " '4818': 102,\n",
       " '0': 103,\n",
       " 'p': 104,\n",
       " '0001': 105,\n",
       " '3715': 106,\n",
       " '4': 107,\n",
       " '005': 108,\n",
       " '157': 109,\n",
       " '5326': 110,\n",
       " '869': 111,\n",
       " '298144': 112,\n",
       " 'respectively': 113,\n",
       " 'differences': 114,\n",
       " 'remained': 115,\n",
       " 'significant': 116,\n",
       " 'rheumatology': 117,\n",
       " 'clinical': 118,\n",
       " 'trialsosteoarthritis': 119,\n",
       " 'research': 120,\n",
       " 'society': 121,\n",
       " 'international': 122,\n",
       " 'responder': 123,\n",
       " 'rate': 124,\n",
       " '65': 125,\n",
       " '34': 126,\n",
       " 'shortterm': 127,\n",
       " 'longer': 128,\n",
       " 'resulting': 129,\n",
       " 'less': 130,\n",
       " 'better': 131,\n",
       " 'attenuation': 132,\n",
       " 'clinicaltrialsgov': 133,\n",
       " 'identifier': 134,\n",
       " 'nct01619163': 135,\n",
       " 'emotional': 136,\n",
       " 'eating': 137,\n",
       " 'associated': 138,\n",
       " 'overeating': 139,\n",
       " 'development': 140,\n",
       " 'obesity': 141,\n",
       " 'yet': 142,\n",
       " 'empirical': 143,\n",
       " 'evidence': 144,\n",
       " 'individual': 145,\n",
       " 'trait': 146,\n",
       " 'cognitive': 147,\n",
       " 'mechanisms': 148,\n",
       " 'contribute': 149,\n",
       " 'sad': 150,\n",
       " 'mood': 151,\n",
       " 'remain': 152,\n",
       " 'equivocal': 153,\n",
       " 'aim': 154,\n",
       " 'study': 155,\n",
       " 'test': 156,\n",
       " 'attention': 157,\n",
       " 'bias': 158,\n",
       " 'food': 159,\n",
       " 'moderates': 160,\n",
       " 'selfreported': 161,\n",
       " 'vs': 162,\n",
       " 'neutral': 163,\n",
       " 'actual': 164,\n",
       " 'intake': 165,\n",
       " 'epected': 166,\n",
       " 'predictive': 167,\n",
       " 'elevated': 168,\n",
       " 'higher': 169,\n",
       " 'eperimentally': 170,\n",
       " 'induced': 171,\n",
       " 'attentional': 172,\n",
       " 'maintenance': 173,\n",
       " 'predicts': 174,\n",
       " 'versus': 175,\n",
       " 'participants': 176,\n",
       " 'n': 177,\n",
       " '85': 178,\n",
       " 'randomly': 179,\n",
       " 'assigned': 180,\n",
       " 'one': 181,\n",
       " 'two': 182,\n",
       " 'eperimental': 183,\n",
       " 'induction': 184,\n",
       " 'conditions': 185,\n",
       " 'biases': 186,\n",
       " 'high': 187,\n",
       " 'caloric': 188,\n",
       " 'foods': 189,\n",
       " 'eye': 190,\n",
       " 'tracking': 191,\n",
       " 'probe': 192,\n",
       " 'task': 193,\n",
       " 'pictorial': 194,\n",
       " 'stimuli': 195,\n",
       " 'dutch': 196,\n",
       " 'behavior': 197,\n",
       " 'questionnaire': 198,\n",
       " 'debq': 199,\n",
       " 'ad': 200,\n",
       " 'libitum': 201,\n",
       " 'tested': 202,\n",
       " 'disguised': 203,\n",
       " 'offer': 204,\n",
       " 'hierarchical': 205,\n",
       " 'multivariate': 206,\n",
       " 'regression': 207,\n",
       " 'modeling': 208,\n",
       " 'showed': 209,\n",
       " 'account': 210,\n",
       " 'changes': 211,\n",
       " 'allocation': 212,\n",
       " 'either': 213,\n",
       " 'condition': 214,\n",
       " 'cues': 215,\n",
       " 'significantly': 216,\n",
       " 'related': 217,\n",
       " 'increased': 218,\n",
       " 'specifically': 219,\n",
       " 'current': 220,\n",
       " 'findings': 221,\n",
       " 'show': 222,\n",
       " 'based': 223,\n",
       " 'might': 224,\n",
       " 'validly': 225,\n",
       " 'predict': 226,\n",
       " 'overeats': 227,\n",
       " 'least': 228,\n",
       " 'laboratory': 229,\n",
       " 'setting': 230,\n",
       " 'healthy': 231,\n",
       " 'women': 232,\n",
       " 'results': 233,\n",
       " 'suggest': 234,\n",
       " 'relates': 235,\n",
       " 'motivation': 236,\n",
       " 'affective': 237,\n",
       " 'state': 238,\n",
       " 'therefore': 239,\n",
       " 'mechanism': 240,\n",
       " 'contributing': 241,\n",
       " 'general': 242,\n",
       " 'maybe': 243,\n",
       " 'although': 244,\n",
       " 'working': 245,\n",
       " 'smoke': 246,\n",
       " 'alarms': 247,\n",
       " 'halve': 248,\n",
       " 'deaths': 249,\n",
       " 'residential': 250,\n",
       " 'fires': 251,\n",
       " 'many': 252,\n",
       " 'households': 253,\n",
       " 'keep': 254,\n",
       " 'operational': 255,\n",
       " 'theorybased': 256,\n",
       " 'education': 257,\n",
       " 'increases': 258,\n",
       " 'alarm': 259,\n",
       " 'operability': 260,\n",
       " 'randomised': 261,\n",
       " 'multiarm': 262,\n",
       " 'trial': 263,\n",
       " 'single': 264,\n",
       " 'arm': 265,\n",
       " 'selected': 266,\n",
       " 'use': 267,\n",
       " 'lowincome': 268,\n",
       " 'neighbourhoods': 269,\n",
       " 'maryland': 270,\n",
       " 'usa': 271,\n",
       " 'full': 272,\n",
       " 'combining': 273,\n",
       " 'health': 274,\n",
       " 'belief': 275,\n",
       " 'module': 276,\n",
       " 'socialcognitive': 277,\n",
       " 'theory': 278,\n",
       " 'provided': 279,\n",
       " 'handson': 280,\n",
       " 'practice': 281,\n",
       " 'installing': 282,\n",
       " 'batteries': 283,\n",
       " 'hush': 284,\n",
       " 'button': 285,\n",
       " '2': 286,\n",
       " 'supplemented': 287,\n",
       " 'typical': 288,\n",
       " 'fire': 289,\n",
       " 'department': 290,\n",
       " '3': 291,\n",
       " 'norm': 292,\n",
       " 'receiving': 293,\n",
       " 'four': 294,\n",
       " 'hundred': 295,\n",
       " 'thirtysi': 296,\n",
       " 'homes': 297,\n",
       " 'recruited': 298,\n",
       " 'churches': 299,\n",
       " 'knocking': 300,\n",
       " 'doors': 301,\n",
       " '20052008': 302,\n",
       " 'followup': 303,\n",
       " 'visits': 304,\n",
       " 'checked': 305,\n",
       " '370': 306,\n",
       " '13': 307,\n",
       " '5': 308,\n",
       " 'years': 309,\n",
       " 'installation': 310,\n",
       " 'number': 311,\n",
       " 'defined': 312,\n",
       " 'hardwired': 313,\n",
       " 'per': 314,\n",
       " 'home': 315,\n",
       " 'regressions': 316,\n",
       " 'controlled': 317,\n",
       " 'status': 318,\n",
       " 'preintervention': 319,\n",
       " 'demographics': 320,\n",
       " 'beliefs': 321,\n",
       " 'risks': 322,\n",
       " 'effectiveness': 323,\n",
       " 'likely': 324,\n",
       " 'functioning': 325,\n",
       " '277': 326,\n",
       " '703': 327,\n",
       " 'average': 328,\n",
       " '032': 329,\n",
       " '009': 330,\n",
       " '056': 331,\n",
       " 'rose': 332,\n",
       " '16': 333,\n",
       " 'similar': 334,\n",
       " '097': 335,\n",
       " 'without': 336,\n",
       " 'eceeding': 337,\n",
       " 'time': 338,\n",
       " 'installers': 339,\n",
       " 'achieve': 340,\n",
       " 'greater': 341,\n",
       " 'key': 342,\n",
       " 'every': 343,\n",
       " 'three': 344,\n",
       " 'additional': 345,\n",
       " 'http': 346,\n",
       " 'wwwclinicaltrialsgov': 347,\n",
       " 'nct00139126': 348,\n",
       " 'evaluate': 349,\n",
       " 'performance': 350,\n",
       " 'safety': 351,\n",
       " 'acceptability': 352,\n",
       " 'new': 353,\n",
       " 'microadherent': 354,\n",
       " 'absorbent': 355,\n",
       " 'dressing': 356,\n",
       " 'urgoclean': 357,\n",
       " 'hydrofiber': 358,\n",
       " 'aquacel': 359,\n",
       " 'local': 360,\n",
       " 'management': 361,\n",
       " 'venous': 362,\n",
       " 'leg': 363,\n",
       " 'ulcers': 364,\n",
       " 'debridement': 365,\n",
       " 'stage': 366,\n",
       " 'noninferiority': 367,\n",
       " 'european': 368,\n",
       " 'rct': 369,\n",
       " 'conducted': 370,\n",
       " '37': 371,\n",
       " 'centres': 372,\n",
       " 'presenting': 373,\n",
       " 'predominantly': 374,\n",
       " 'mied': 375,\n",
       " 'aetiology': 376,\n",
       " 'sloughy': 377,\n",
       " '70': 378,\n",
       " 'wound': 379,\n",
       " 'bed': 380,\n",
       " 'covered': 381,\n",
       " 'slough': 382,\n",
       " 'baseline': 383,\n",
       " 'followed': 384,\n",
       " '6week': 385,\n",
       " 'period': 386,\n",
       " 'weekly': 387,\n",
       " 'judgement': 388,\n",
       " 'criteria': 389,\n",
       " 'relative': 390,\n",
       " 'surface': 391,\n",
       " 'area': 392,\n",
       " 'endpoints': 393,\n",
       " 'tissue': 394,\n",
       " 'percentage': 395,\n",
       " 'debrided': 396,\n",
       " 'altogether': 397,\n",
       " '159': 398,\n",
       " '83': 399,\n",
       " 'control': 400,\n",
       " '76': 401,\n",
       " 'dressings': 402,\n",
       " 'regarding': 403,\n",
       " 'healing': 404,\n",
       " 'process': 405,\n",
       " 'factors': 406,\n",
       " 'duration': 407,\n",
       " 'abpi': 408,\n",
       " 'value': 409,\n",
       " 'recurrence': 410,\n",
       " 'groups': 411,\n",
       " 'well': 412,\n",
       " 'balanced': 413,\n",
       " 'characteristics': 414,\n",
       " 'compression': 415,\n",
       " 'therapy': 416,\n",
       " 'administered': 417,\n",
       " 'median': 418,\n",
       " '42day': 419,\n",
       " '369': 420,\n",
       " '354': 421,\n",
       " 'considering': 422,\n",
       " 'week': 423,\n",
       " '653': 424,\n",
       " '42': 425,\n",
       " '0013': 426,\n",
       " 'wounds': 427,\n",
       " 'also': 428,\n",
       " '525': 429,\n",
       " '351': 430,\n",
       " '0033': 431,\n",
       " 'earth': 432,\n",
       " 'confirmed': 433,\n",
       " 'however': 434,\n",
       " 'autolytic': 435,\n",
       " 'properties': 436,\n",
       " 'represents': 437,\n",
       " 'promising': 438,\n",
       " 'therapeutic': 439,\n",
       " 'option': 440,\n",
       " 'within': 441,\n",
       " 'range': 442,\n",
       " 'available': 443,\n",
       " 'sponsored': 444,\n",
       " 'grant': 445,\n",
       " 'pharmaceutical': 446,\n",
       " 'company': 447,\n",
       " 'laboratoires': 448,\n",
       " 'urgo': 449,\n",
       " 'bohbot': 450,\n",
       " 'tacca': 451,\n",
       " 'employees': 452,\n",
       " 'meaume': 453,\n",
       " 'j': 454,\n",
       " 'dissemond': 455,\n",
       " 'g': 456,\n",
       " 'perceau': 457,\n",
       " 'monetary': 458,\n",
       " 'compensation': 459,\n",
       " 'presenters': 460,\n",
       " 'data': 461,\n",
       " 'statistical': 462,\n",
       " 'analyses': 463,\n",
       " 'independently': 464,\n",
       " 'vertical': 465,\n",
       " 'paris': 466,\n",
       " 'france': 467,\n",
       " 'movements': 468,\n",
       " 'em': 469,\n",
       " 'recall': 470,\n",
       " 'aversive': 471,\n",
       " 'memory': 472,\n",
       " 'element': 473,\n",
       " 'unique': 474,\n",
       " 'movement': 475,\n",
       " 'desensitization': 476,\n",
       " 'reprocessing': 477,\n",
       " 'emdr': 478,\n",
       " 'studies': 479,\n",
       " 'shown': 480,\n",
       " 'reduce': 481,\n",
       " 'vividness': 482,\n",
       " 'emotionality': 483,\n",
       " 'shortly': 484,\n",
       " 'unclear': 485,\n",
       " 'immediate': 486,\n",
       " 'effects': 487,\n",
       " 'reflect': 488,\n",
       " 'reductions': 489,\n",
       " 'persist': 490,\n",
       " '24h': 491,\n",
       " 'follow': 492,\n",
       " 'magnitude': 493,\n",
       " 'seventythree': 494,\n",
       " 'undergraduates': 495,\n",
       " 'recalled': 496,\n",
       " 'negative': 497,\n",
       " 'autobiographical': 498,\n",
       " 'memories': 499,\n",
       " 'half': 500,\n",
       " 'periods': 501,\n",
       " '24s': 502,\n",
       " 'eight': 503,\n",
       " 'selfrated': 504,\n",
       " 'pretest': 505,\n",
       " 'posttest': 506,\n",
       " 'caused': 507,\n",
       " 'decrease': 508,\n",
       " 'furthermore': 509,\n",
       " 'selfreport': 510,\n",
       " 'used': 511,\n",
       " 'causes': 512,\n",
       " '24hchanges': 513,\n",
       " 'may': 514,\n",
       " 'eplain': 515,\n",
       " 'part': 516,\n",
       " 'impact': 517,\n",
       " 'motivational': 518,\n",
       " 'interviewing': 519,\n",
       " 'mi': 520,\n",
       " 'delivered': 521,\n",
       " 'care': 522,\n",
       " 'providers': 523,\n",
       " 'pediatric': 524,\n",
       " 'registered': 525,\n",
       " 'dietitians': 526,\n",
       " 'rds': 527,\n",
       " 'parents': 528,\n",
       " 'overweight': 529,\n",
       " 'children': 530,\n",
       " 'aged': 531,\n",
       " '8': 532,\n",
       " 'fortytwo': 533,\n",
       " 'practices': 534,\n",
       " 'office': 535,\n",
       " 'settings': 536,\n",
       " 'network': 537,\n",
       " 'american': 538,\n",
       " 'academy': 539,\n",
       " 'pediatrics': 540,\n",
       " 'usual': 541,\n",
       " 'bmi': 542,\n",
       " 'percentile': 543,\n",
       " '2year': 544,\n",
       " 'provider': 545,\n",
       " 'counseling': 546,\n",
       " 'sessions': 547,\n",
       " 'child': 548,\n",
       " '+': 549,\n",
       " 'rd': 550,\n",
       " 'plus': 551,\n",
       " 'adjusted': 552,\n",
       " '903': 553,\n",
       " '881': 554,\n",
       " '871': 555,\n",
       " '02': 556,\n",
       " 'lower': 557,\n",
       " '18': 558,\n",
       " '38': 559,\n",
       " '49': 560,\n",
       " 'across': 561,\n",
       " 'resulted': 562,\n",
       " 'statistically': 563,\n",
       " 'needed': 564,\n",
       " 'determine': 565,\n",
       " 'significance': 566,\n",
       " 'persistence': 567,\n",
       " 'observed': 568,\n",
       " 'brought': 569,\n",
       " 'particular': 570,\n",
       " 'train': 571,\n",
       " 'physicians': 572,\n",
       " 'effectively': 573,\n",
       " 'best': 574,\n",
       " 'integrate': 575,\n",
       " 'merits': 576,\n",
       " 'future': 577,\n",
       " 'antithrombin': 578,\n",
       " 'concentrations': 579,\n",
       " 'reduced': 580,\n",
       " 'cardiac': 581,\n",
       " 'surgery': 582,\n",
       " 'cardiopulmonary': 583,\n",
       " 'bypass': 584,\n",
       " 'preoperative': 585,\n",
       " 'low': 586,\n",
       " 'postoperative': 587,\n",
       " 'worse': 588,\n",
       " 'midterm': 589,\n",
       " 'outcomes': 590,\n",
       " 'administration': 591,\n",
       " 'activation': 592,\n",
       " 'coagulation': 593,\n",
       " 'fibrinolytic': 594,\n",
       " 'systems': 595,\n",
       " 'platelet': 596,\n",
       " 'inflammatory': 597,\n",
       " 'response': 598,\n",
       " 'sity': 599,\n",
       " 'receive': 600,\n",
       " 'purified': 601,\n",
       " '5000': 602,\n",
       " 'iu': 603,\n",
       " 'administrations': 604,\n",
       " 'intensive': 605,\n",
       " 'unit': 606,\n",
       " 'thirty': 607,\n",
       " 'controls': 608,\n",
       " 'marker': 609,\n",
       " 'prothrombin': 610,\n",
       " 'fragment': 611,\n",
       " 'thrombin': 612,\n",
       " 'generation': 613,\n",
       " 'plasminantiplasmin': 614,\n",
       " 'comple': 615,\n",
       " 'fibrinolysis': 616,\n",
       " 'si': 617,\n",
       " 'different': 618,\n",
       " 'times': 619,\n",
       " 'values': 620,\n",
       " '48': 621,\n",
       " 'hours': 622,\n",
       " 'last': 623,\n",
       " 'analysis': 624,\n",
       " 'variance': 625,\n",
       " 'repeated': 626,\n",
       " 'reducing': 627,\n",
       " '0009': 628,\n",
       " 'interaction': 629,\n",
       " 'sample': 630,\n",
       " '0006': 631,\n",
       " '0877': 632,\n",
       " '0521': 633,\n",
       " '0913': 634,\n",
       " '0543': 635,\n",
       " 'chest': 636,\n",
       " 'tube': 637,\n",
       " 'drainage': 638,\n",
       " 'reopening': 639,\n",
       " 'bleeding': 640,\n",
       " 'blood': 641,\n",
       " 'transfusion': 642,\n",
       " 'activity': 643,\n",
       " 'reduces': 644,\n",
       " 'evaluated': 645,\n",
       " 'tertiary': 646,\n",
       " 'percutaneous': 647,\n",
       " 'coronary': 648,\n",
       " 'pci': 649,\n",
       " 'artery': 650,\n",
       " 'grafting': 651,\n",
       " 'cabg': 652,\n",
       " 'capable': 653,\n",
       " 'hospitals': 654,\n",
       " 'earlyacs': 655,\n",
       " 'early': 656,\n",
       " 'invasive': 657,\n",
       " 'recommended': 658,\n",
       " 'highrisk': 659,\n",
       " 'nonstsegment': 660,\n",
       " 'elevation': 661,\n",
       " 'acute': 662,\n",
       " 'syndromes': 663,\n",
       " '9': 664,\n",
       " '204': 665,\n",
       " 'sites': 666,\n",
       " 'transfer': 667,\n",
       " 'transferred': 668,\n",
       " 'nontransfer': 669,\n",
       " '348': 670,\n",
       " '7': 671,\n",
       " '455': 672,\n",
       " '89': 673,\n",
       " '749': 674,\n",
       " '729': 675,\n",
       " '020': 676,\n",
       " 'delays': 677,\n",
       " 'occurred': 678,\n",
       " 'symptom': 679,\n",
       " 'onset': 680,\n",
       " 'angiography': 681,\n",
       " 'hr': 682,\n",
       " '53h': 683,\n",
       " '178': 684,\n",
       " '30day': 685,\n",
       " 'death': 686,\n",
       " 'myocardial': 687,\n",
       " 'infarction': 688,\n",
       " '94': 689,\n",
       " '117': 690,\n",
       " 'odds': 691,\n",
       " 'ratio': 692,\n",
       " '078': 693,\n",
       " '0620': 694,\n",
       " '97': 695,\n",
       " '0026': 696,\n",
       " '140': 697,\n",
       " '123': 698,\n",
       " '0981': 699,\n",
       " '53': 700,\n",
       " '0074': 701,\n",
       " '1year': 702,\n",
       " 'mortality': 703,\n",
       " '43': 704,\n",
       " 'hazard': 705,\n",
       " '064': 706,\n",
       " '0470': 707,\n",
       " '87': 708,\n",
       " '0005': 709,\n",
       " '52': 710,\n",
       " '080': 711,\n",
       " '0581': 712,\n",
       " '0202': 713,\n",
       " 'despite': 714,\n",
       " 'rates': 715,\n",
       " 'catheterization': 716,\n",
       " 'gusto': 717,\n",
       " '120': 718,\n",
       " '31': 719,\n",
       " '67': 720,\n",
       " '047': 721,\n",
       " '0320': 722,\n",
       " '68': 723,\n",
       " 'whereas': 724,\n",
       " '61': 725,\n",
       " '094': 726,\n",
       " '0681': 727,\n",
       " '30': 728,\n",
       " '0693': 729,\n",
       " 'noncabg': 730,\n",
       " 'timely': 731,\n",
       " 'revascularization': 732,\n",
       " 'often': 733,\n",
       " 'achieved': 734,\n",
       " 'nontransferred': 735,\n",
       " 'lowest': 736,\n",
       " 'event': 737,\n",
       " 'longterm': 738,\n",
       " 'survival': 739,\n",
       " 'hypothesized': 740,\n",
       " 'targeted': 741,\n",
       " 'temperature': 742,\n",
       " '33': 743,\n",
       " 'c': 744,\n",
       " '36': 745,\n",
       " 'increase': 746,\n",
       " 'circulatory': 747,\n",
       " 'shock': 748,\n",
       " 'admission': 749,\n",
       " 'outofhospital': 750,\n",
       " 'arrest': 751,\n",
       " 'ohca': 752,\n",
       " 'recently': 753,\n",
       " 'published': 754,\n",
       " 'target': 755,\n",
       " 'ttmtrial': 756,\n",
       " '939': 757,\n",
       " 'end': 758,\n",
       " 'predefined': 759,\n",
       " 'subgroup': 760,\n",
       " 'systolic': 761,\n",
       " 'pressure': 762,\n",
       " '90': 763,\n",
       " 'hg': 764,\n",
       " 'min': 765,\n",
       " 'need': 766,\n",
       " 'supportive': 767,\n",
       " 'maintain': 768,\n",
       " 'mmhg': 769,\n",
       " 'signs': 770,\n",
       " 'endorgan': 771,\n",
       " 'hypoperfusion': 772,\n",
       " 'post': 773,\n",
       " 'hoc': 774,\n",
       " 'reported': 775,\n",
       " 'analyzed': 776,\n",
       " '139': 777,\n",
       " 'ttm33': 778,\n",
       " '71': 779,\n",
       " 'ttm36': 780,\n",
       " '180day': 781,\n",
       " 'icu': 782,\n",
       " 'arterial': 783,\n",
       " 'lactate': 784,\n",
       " 'fluid': 785,\n",
       " 'balance': 786,\n",
       " 'etended': 787,\n",
       " 'sequential': 788,\n",
       " 'organ': 789,\n",
       " 'failure': 790,\n",
       " 'sofa': 791,\n",
       " 'score': 792,\n",
       " 'logrank': 793,\n",
       " '017': 794,\n",
       " '133': 795,\n",
       " 'confidence': 796,\n",
       " 'interval': 797,\n",
       " '0881': 798,\n",
       " '98': 799,\n",
       " '44': 800,\n",
       " '006': 801,\n",
       " 'risk': 802,\n",
       " '137': 803,\n",
       " '0991': 804,\n",
       " '91': 805,\n",
       " 'cardiovascular': 806,\n",
       " '001': 807,\n",
       " 'found': 808,\n",
       " 'benefit': 809,\n",
       " 'youths': 810,\n",
       " 'family': 811,\n",
       " 'history': 812,\n",
       " 'alcohol': 813,\n",
       " 'drug': 814,\n",
       " 'disorders': 815,\n",
       " 'fh': 816,\n",
       " 'developing': 817,\n",
       " 'substance': 818,\n",
       " 'peers': 819,\n",
       " 'histories': 820,\n",
       " 'impaired': 821,\n",
       " 'maturation': 822,\n",
       " 'forebrain': 823,\n",
       " 'circuitry': 824,\n",
       " 'individuals': 825,\n",
       " 'altered': 826,\n",
       " 'rest': 827,\n",
       " 'performing': 828,\n",
       " 'tasks': 829,\n",
       " 'fully': 830,\n",
       " 'understood': 831,\n",
       " 'ultimately': 832,\n",
       " 'alterations': 833,\n",
       " 'disorder': 834,\n",
       " '72': 835,\n",
       " '32': 836,\n",
       " 'go': 837,\n",
       " 'nogo': 838,\n",
       " 'eamined': 839,\n",
       " 'activations': 840,\n",
       " 'blocks': 841,\n",
       " 'trials': 842,\n",
       " '50': 843,\n",
       " 'contrast': 844,\n",
       " 'cerebral': 845,\n",
       " 'regions': 846,\n",
       " 'including': 847,\n",
       " 'posterior': 848,\n",
       " 'cingulate': 849,\n",
       " 'precuneus': 850,\n",
       " 'bilateral': 851,\n",
       " 'middle': 852,\n",
       " 'superior': 853,\n",
       " 'temporal': 854,\n",
       " 'gyrus': 855,\n",
       " 'medial': 856,\n",
       " 'frontal': 857,\n",
       " 'subtraction': 858,\n",
       " 'additionally': 859,\n",
       " 'moderately': 860,\n",
       " 'slower': 861,\n",
       " 'reaction': 862,\n",
       " 'modulated': 863,\n",
       " 'density': 864,\n",
       " 'specific': 865,\n",
       " 'inhibitory': 866,\n",
       " 'components': 867,\n",
       " 'pattern': 868,\n",
       " 'partially': 869,\n",
       " 'due': 870,\n",
       " 'white': 871,\n",
       " 'matter': 872,\n",
       " 'leading': 873,\n",
       " 'efficient': 874,\n",
       " 'neural': 875,\n",
       " 'communication': 876,\n",
       " 'proposed': 877,\n",
       " 'running': 878,\n",
       " 'injuries': 879,\n",
       " 'muscular': 880,\n",
       " 'strength': 881,\n",
       " 'b': 882,\n",
       " 'ecessive': 883,\n",
       " 'joint': 884,\n",
       " 'moments': 885,\n",
       " 'transverse': 886,\n",
       " 'planes': 887,\n",
       " 'date': 888,\n",
       " 'injury': 889,\n",
       " 'prevention': 890,\n",
       " 'programs': 891,\n",
       " 'focused': 892,\n",
       " 'top': 893,\n",
       " 'approach': 894,\n",
       " 'strengthen': 895,\n",
       " 'hip': 896,\n",
       " 'musculature': 897,\n",
       " 'attempt': 898,\n",
       " 'ankle': 899,\n",
       " 'joints': 900,\n",
       " 'mechanics': 901,\n",
       " 'change': 902,\n",
       " 'muscle': 903,\n",
       " 'could': 904,\n",
       " 'speculated': 905,\n",
       " 'emphasis': 906,\n",
       " 'placed': 907,\n",
       " 'increasing': 908,\n",
       " 'ground': 909,\n",
       " 'strengthening': 910,\n",
       " 'large': 911,\n",
       " 'small': 912,\n",
       " 'muscles': 913,\n",
       " 'crossing': 914,\n",
       " 'assumed': 915,\n",
       " 'force': 916,\n",
       " 'distribution': 917,\n",
       " 'smaller': 918,\n",
       " 'insertion': 919,\n",
       " 'forces': 920,\n",
       " 'beneficial': 921,\n",
       " 'training': 922,\n",
       " 'strategy': 923,\n",
       " 'studied': 924,\n",
       " 'techniques': 925,\n",
       " 'include': 926,\n",
       " 'isolated': 927,\n",
       " 'movementrelated': 928,\n",
       " 'functional': 929,\n",
       " 'little': 930,\n",
       " 'knowledge': 931,\n",
       " 'alteration': 932,\n",
       " 'gait': 933,\n",
       " 'novice': 934,\n",
       " 'runners': 935,\n",
       " '40': 936,\n",
       " 'activitymatched': 937,\n",
       " 'isokinetic': 938,\n",
       " 'biode': 939,\n",
       " 'system': 940,\n",
       " 'dynamometer': 941,\n",
       " 'kinematics': 942,\n",
       " 'kinetics': 943,\n",
       " '3d': 944,\n",
       " 'motion': 945,\n",
       " 'platform': 946,\n",
       " 'postural': 947,\n",
       " 'quantifying': 948,\n",
       " 'structure': 949,\n",
       " 'center': 950,\n",
       " 'trace': 951,\n",
       " 'stance': 952,\n",
       " 'pre': 953,\n",
       " 'posttraining': 954,\n",
       " 'variables': 955,\n",
       " 'following': 956,\n",
       " 'interventions': 957,\n",
       " '6months': 958,\n",
       " 'avoiding': 959,\n",
       " 'allow': 960,\n",
       " 'enjoy': 961,\n",
       " 'benefits': 962,\n",
       " 'participating': 963,\n",
       " 'aerobic': 964,\n",
       " 'activities': 965,\n",
       " 'healthcare': 966,\n",
       " 'costs': 967,\n",
       " 'nct01900262': 968,\n",
       " 'vitamin': 969,\n",
       " 'b12': 970,\n",
       " 'deficiency': 971,\n",
       " 'neurologic': 972,\n",
       " 'psychiatric': 973,\n",
       " 'disease': 974,\n",
       " 'especially': 975,\n",
       " 'subacute': 976,\n",
       " 'combined': 977,\n",
       " 'degeneration': 978,\n",
       " 'characterized': 979,\n",
       " 'damage': 980,\n",
       " 'lateral': 981,\n",
       " 'spinal': 982,\n",
       " 'cord': 983,\n",
       " 'affecting': 984,\n",
       " 'corticospinal': 985,\n",
       " 'tract': 986,\n",
       " 'projections': 987,\n",
       " 'motor': 988,\n",
       " 'evoked': 989,\n",
       " 'potentials': 990,\n",
       " 'meps': 991,\n",
       " 'transcranial': 992,\n",
       " 'magnetic': 993,\n",
       " 'stimulation': 994,\n",
       " 'tms': 995,\n",
       " 'asymptomatic': 996,\n",
       " 'crosssectional': 997,\n",
       " 'recorded': 998,\n",
       " 'abductor': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_pickle('../data/abstracts_data/20k_abstracts/processed_train.pickle')\n",
    "test_df=pd.read_pickle('../data/abstracts_data/20k_abstracts/processed_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(label):\n",
    "    if label == \"RESULTS\":\n",
    "        return 0\n",
    "    elif label == \"METHODS\":\n",
    "        return 1\n",
    "    elif label == \"CONCLUSIONS\":\n",
    "        return 2\n",
    "    elif label == \"BACKGROUND\":\n",
    "        return 3\n",
    "    else: #positive\n",
    "        return 4\n",
    "\n",
    "seq_length = 194\n",
    "def encode_and_pad(tweet, length):\n",
    "    sos = [word2index[\"<SOS>\"]]\n",
    "    eos = [word2index[\"<EOS>\"]]\n",
    "    pad = [word2index[\"<PAD>\"]]\n",
    "\n",
    "    if len(tweet) < length - 2: # -2 for SOS and EOS\n",
    "        n_pads = length - 2 - len(tweet)\n",
    "        encoded = [word2index[w] for w in tweet]\n",
    "        return sos + encoded + eos + pad * n_pads \n",
    "    else: # tweet is longer than possible; truncating\n",
    "        encoded = [word2index[w] for w in tweet]\n",
    "        truncated = encoded[:length - 2]\n",
    "        return sos + truncated + eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(label, tokens) for label, tokens in zip(train_df['target'], train_df['text_tokens'])]\n",
    "test_set = [(label, tokens) for label, tokens in zip(test_df['target'], test_df['text_tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = [(encode_and_pad(tweet, seq_length), label_map(label)) for label, tweet in train_set]\n",
    "test_encoded = [(encode_and_pad(tweet, seq_length), label_map(label)) for label, tweet in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "train_x = np.array([tweet for tweet, label in train_encoded])\n",
    "train_y = np.array([label for tweet, label in train_encoded])\n",
    "test_x = np.array([tweet for tweet, label in test_encoded])\n",
    "test_y = np.array([label for tweet, label in test_encoded])\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_SentimentAnalysis(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout) :\n",
    "        super().__init__()\n",
    "\n",
    "        # The embedding layer takes the vocab size and the embeddings size as input\n",
    "        # The embeddings size is up to you to decide, but common sizes are between 50 and 100.\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM layer takes in the the embedding size and the hidden vector size.\n",
    "        # The hidden dimension is up to you to decide, but common values are 32, 64, 128\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # We use dropout before the final layer to improve with regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # The fully-connected layer takes in the hidden dim of the LSTM and\n",
    "        #  outputs a a 3x1 vector of the class scores.\n",
    "        self.fc = nn.Linear(hidden_dim, 5)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        The forward method takes in the input and the previous hidden state \n",
    "        \"\"\"\n",
    "\n",
    "        # The input is transformed to embeddings by passing it to the embedding layer\n",
    "        embs = self.embedding(x)\n",
    "\n",
    "        # The embedded inputs are fed to the LSTM alongside the previous hidden state\n",
    "        out, hidden = self.lstm(embs, hidden)\n",
    "\n",
    "        # Dropout is applied to the output and fed to the FC layer\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # We extract the scores for the final hidden state since it is the one that matters.\n",
    "        out = out[:, -1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, batch_size, 32), torch.zeros(1, batch_size, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_mps = torch.backends.mps.is_available()\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = BiLSTM_SentimentAnalysis(len(word2index), 64, 32, 0.2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_SentimentAnalysis(\n",
       "  (embedding): Embedding(91942, 64, padding_idx=0)\n",
       "  (lstm): LSTM(64, 32, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6222d8d67b6149579262a5fca60d43b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "losses = []\n",
    "for e in range(epochs):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(e))\n",
    "    \n",
    "    h0, c0 =  model.init_hidden()\n",
    "\n",
    "    h0 = h0.to(device)\n",
    "    c0 = c0.to(device)\n",
    "\n",
    "    for batch in tqdm(train_dl):\n",
    "\n",
    "        input = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            out, hidden = model(input, (h0, c0))\n",
    "#             print(out.shape)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f35101604f0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed:1.5257616452872753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32837209302325615"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "batch_acc = []\n",
    "t0 = time.perf_counter()\n",
    "for batch_idx, batch in enumerate(test_dl):\n",
    "    \n",
    "    input = batch[0].to(device)\n",
    "    target = batch[1].to(device)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        out, hidden = model(input, (h0, c0))\n",
    "#         print(out)\n",
    "#         print(F.softmax(out))\n",
    "        preds = torch.argmax(F.softmax(out, dim=1),1)\n",
    "        preds = preds.to(\"cpu\").tolist()\n",
    "        batch_acc.append(accuracy_score(preds, target.tolist()))\n",
    "time_elapsed = time.perf_counter() - t0\n",
    "print('Time Elapsed:{}'.format(time_elapsed))\n",
    "\n",
    "sum(batch_acc)/len(batch_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla V100-SXM2-32GB</td>\n",
       "      <td>1.492147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 device      time\n",
       "0  Tesla V100-SXM2-32GB  1.492147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame()\n",
    "df['device']=[torch.cuda.get_device_name(0)]\n",
    "df['time']=[time_elapsed]\n",
    "df.to_csv('pt_text_classification_time_elapsed_'+f'{torch.cuda.get_device_name(0)}.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/pt_text_classification_model_'+f'{torch.cuda.get_device_name(0)}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Crypten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --user crypten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ss4yd/.local/lib/python3.8/site-packages/crypten/__init__.py:64: RuntimeWarning: CrypTen is already initialized.\n",
      "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "import crypten\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "number of outputs should be 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Elapsed:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time_elapsed))\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m time_elapsed\n\u001b[0;32m---> 31\u001b[0m time\u001b[38;5;241m=\u001b[39m\u001b[43mget_time_elapsed_crypten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [23], line 5\u001b[0m, in \u001b[0;36mget_time_elapsed_crypten\u001b[0;34m(device, test_loader, hidden)\u001b[0m\n\u001b[1;32m      2\u001b[0m plaintext_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/pt_text_classification_model_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), (h0\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), c0\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m private_model \u001b[38;5;241m=\u001b[39m \u001b[43mcrypten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaintext_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m private_model\u001b[38;5;241m.\u001b[39mencrypt(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m private_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:46\u001b[0m, in \u001b[0;36mfrom_pytorch\u001b[0;34m(pytorch_model, dummy_input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# construct CrypTen model:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m f \u001b[38;5;241m=\u001b[39m _from_pytorch_to_bytes(pytorch_model, dummy_input)\n\u001b[0;32m---> 46\u001b[0m crypten_model \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# make sure training / eval setting is copied:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:35\u001b[0m, in \u001b[0;36mfrom_onnx\u001b[0;34m(onnx_string_or_file)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mConverts an ONNX model serialized in an `onnx_string_or_file` to a CrypTen model.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m _load_onnx_model(onnx_string_or_file)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_crypten\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:155\u001b[0m, in \u001b[0;36m_to_crypten\u001b[0;34m(onnx_model)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mFunction that converts an `onnx_model` to a CrypTen model.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# create graph:\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m input_names, output_names \u001b[38;5;241m=\u001b[39m \u001b[43m_get_input_output_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one output per model supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m crypten_model \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mGraph(input_names, output_names[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:203\u001b[0m, in \u001b[0;36m_get_input_output_names\u001b[0;34m(onnx_model)\u001b[0m\n\u001b[1;32m    201\u001b[0m output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m onnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39moutput]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_names) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of inputs should be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of outputs should be 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_names, output_names\n",
      "\u001b[0;31mAssertionError\u001b[0m: number of outputs should be 1"
     ]
    }
   ],
   "source": [
    "def get_time_elapsed_crypten(device, test_loader, hidden):\n",
    "    plaintext_model = torch.load('./models/pt_text_classification_model_'+f'{torch.cuda.get_device_name(0)}.pth').to('cpu')\n",
    "    dummy_input = input.to('cpu'), (h0.to('cpu'), c0.to('cpu'))\n",
    "\n",
    "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "    private_model.encrypt(src=0)\n",
    "    private_model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        t0 = time.perf_counter()\n",
    "        for data, target in tqdm(test_loader):\n",
    "            target = target\n",
    "            data_enc = crypten.cryptensor(data)\n",
    "            output, hidden = private_model(data_enc, hidden)\n",
    "            output = output_enc.get_plain_text()\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            preds = torch.argmax(F.softmax(output, dim=1),1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        time_elapsed = time.perf_counter() - t0\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))\n",
    "    print('Time Elapsed:{}'.format(time_elapsed))\n",
    "    return time_elapsed\n",
    "\n",
    "time=get_time_elapsed_crypten( device, test_dl, (h0,c0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "number of outputs should be 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m plaintext_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/pt_text_classification_model_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), (h0\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), c0\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m private_model \u001b[38;5;241m=\u001b[39m \u001b[43mcrypten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaintext_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m private_model\u001b[38;5;241m.\u001b[39mencrypt(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m private_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:46\u001b[0m, in \u001b[0;36mfrom_pytorch\u001b[0;34m(pytorch_model, dummy_input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# construct CrypTen model:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m f \u001b[38;5;241m=\u001b[39m _from_pytorch_to_bytes(pytorch_model, dummy_input)\n\u001b[0;32m---> 46\u001b[0m crypten_model \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# make sure training / eval setting is copied:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:35\u001b[0m, in \u001b[0;36mfrom_onnx\u001b[0;34m(onnx_string_or_file)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mConverts an ONNX model serialized in an `onnx_string_or_file` to a CrypTen model.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m _load_onnx_model(onnx_string_or_file)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_crypten\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:155\u001b[0m, in \u001b[0;36m_to_crypten\u001b[0;34m(onnx_model)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mFunction that converts an `onnx_model` to a CrypTen model.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# create graph:\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m input_names, output_names \u001b[38;5;241m=\u001b[39m \u001b[43m_get_input_output_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one output per model supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m crypten_model \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mGraph(input_names, output_names[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/crypten/nn/onnx_converter.py:203\u001b[0m, in \u001b[0;36m_get_input_output_names\u001b[0;34m(onnx_model)\u001b[0m\n\u001b[1;32m    201\u001b[0m output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m onnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39moutput]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_names) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of inputs should be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of outputs should be 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_names, output_names\n",
      "\u001b[0;31mAssertionError\u001b[0m: number of outputs should be 1"
     ]
    }
   ],
   "source": [
    "plaintext_model = torch.load('./models/pt_text_classification_model_'+f'{torch.cuda.get_device_name(0)}.pth').to('cpu')\n",
    "dummy_input = input.to('cpu'), (h0.to('cpu'), c0.to('cpu'))\n",
    "\n",
    "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "private_model.encrypt(src=0)\n",
    "private_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_SentimentAnalysis(\n",
       "  (embedding): Embedding(91942, 64, padding_idx=0)\n",
       "  (lstm): LSTM(64, 32, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaintext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  8374,  2816,  ...,     0,     0,     0],\n",
       "        [    1,   894,   434,  ...,     0,     0,     0],\n",
       "        [    1,    74,    31,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1,   154,  2981,  ...,     0,     0,     0],\n",
       "        [    1,    31,  9794,  ...,     0,     0,     0],\n",
       "        [    1,   463, 34622,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10.0",
   "language": "python",
   "name": "pytorch-1.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
