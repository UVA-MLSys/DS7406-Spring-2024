{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as trns\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images\n",
    "# ls '../datasets/nih-chest-xray/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../datasets/nih-chest-xray/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = dict()\n",
    "for f in os.listdir(data_path):\n",
    "    if os.path.isfile(os.path.join(data_path, f)) and f[-4:] == '.png':\n",
    "        images_list[f] = os.path.join(data_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List full paths\n",
    "# images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/nih-chest-xray/sample_labels.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(img):\n",
    "    plt.imshow(np.array(img) / 255)\n",
    "    \n",
    "def openImage(str_path):\n",
    "    return Image.open(str_path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImage(openImage(images_list[list(images_list.keys())[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'Atelectasis', \n",
    "    'Consolidation', \n",
    "    'Infiltration', \n",
    "    'Pneumothorax', \n",
    "    'Edema', \n",
    "    'Emphysema', \n",
    "    'Fibrosis', \n",
    "    'Effusion', \n",
    "    'Pneumonia', \n",
    "    'Pleural_thickening', \n",
    "    'Cardiomegaly', \n",
    "    'Nodule', \n",
    "    'Mass', \n",
    "    'Hernia', \n",
    "    'No Finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderCompose(Dataset):\n",
    "    def __init__(self, data, transforms):\n",
    "        self.image_paths = [images_list[f] for f in data[0]]\n",
    "        self.labels = data[1]\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(data[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transforms(openImage(self.image_paths[idx]))\n",
    "        target = torch.tensor([int(cls in self.labels[idx]) for cls in classes], dtype=torch.float32)\n",
    "        return (image, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (df.iloc[:5000, 0], [df.iloc[i, 1].split('|') for i in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoaderCompose(data, trns.Compose([\n",
    "    trns.Resize((240, 240)),\n",
    "    trns.ToTensor(), \n",
    "    trns.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],inplace=True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[1][0].permute((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = random_split(dataset, [int(len(dataset) * 0.80), len(dataset) - int(len(dataset) * 0.80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = len(train_dataset)\n",
    "validation_dataset_size = len(validation_dataset)\n",
    "train_dataset_size, validation_dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34(pretrained=True)\n",
    "resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 15\n",
    "input_shape = (3, 240, 240)\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 1e-1\n",
    "\n",
    "epochs_per_client = 1 #5 #If not federated learning model, just epoch number for single client\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants for federated learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 2 #5\n",
    "rounds = 2 #10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Device detected is {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 1: Vanilla PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    _, preds = torch.max(out, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out =self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_loss = [x[\"val_loss\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_loss).mean()\n",
    "        batch_acc = [x[\"val_acc\"] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_acc).mean()\n",
    "        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, epochs, result):\n",
    "        print(\"Epoch: [{}/{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch+1, epochs, result[\"lrs\"][-1], result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))\n",
    "        \n",
    "class ResNet34(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        number_of_features = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(number_of_features, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    \n",
    "    def freeze(self): #by freezing all the layers but the last one we allow it to warm up (the others are already good at training)\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad=False\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad=True\n",
    "            \n",
    "    def unfreeze(self):\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate network\n",
    "model = to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "val_dl = DataLoader(validation_dataset, batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_dl):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "    \n",
    "def train(epochs, max_lr, model, train_dl, val_dl, weight_decay=0,\n",
    "                 grad_clip=None, opt_func=torch.optim.Adam):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    history = []\n",
    "    opt = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr, epochs=epochs,\n",
    "                                               steps_per_epoch=len(train_dl))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_dl):\n",
    "            loss = model.training_step(batch)\n",
    "            train_loss.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "                \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            lrs.append(get_lr(opt))\n",
    "            sched.step()\n",
    "            \n",
    "        result = evaluate(model, val_dl)\n",
    "        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n",
    "        result[\"lrs\"] = lrs\n",
    "        model.epoch_end(epoch, epochs, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(model, val_dl)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = train(epochs_per_client, learning_rate, model, train_dl, val_dl,\n",
    "                        grad_clip=grad_clip, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [x[\"val_acc\"] for x in history]\n",
    "plt.plot(accuracy, \"-bx\")\n",
    "\n",
    "plt.title(\"Acccuracy vs number of epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2: Vanilla federated learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFederatedNetwork(torch.nn.Module):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        self.network.fc = torch.nn.Linear(self.network.fc.in_features, num_classes)\n",
    "        self.track_layers = {\n",
    "            'layer4':  self.network.layer4,\n",
    "            'linear': self.network.fc\n",
    "        }\n",
    "        self.freeze()\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.network.parameters():\n",
    "            param.requires_grad = False\n",
    "        for layer_name in self.track_layers:\n",
    "            for param in self.track_layers[layer_name].parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        out = torch.sigmoid(self.network(x_batch))\n",
    "        return out\n",
    "    \n",
    "    def get_track_layers(self):\n",
    "        return self.track_layers\n",
    "    \n",
    "    def apply_parameters(self, parameters_dict):\n",
    "        with torch.no_grad():\n",
    "            for layer_name in parameters_dict:\n",
    "                layer_params = list(self.track_layers[layer_name].parameters())\n",
    "                for i in range(len(layer_params)):\n",
    "                    layer_params[i].data = (layer_params[i].data + (parameters_dict[layer_name][i] - \n",
    "                                                layer_params[i].data))\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        parameters_dict = dict()\n",
    "        for layer_name in self.track_layers:\n",
    "            parameters_dict[layer_name] = [param.data.clone().detach() for param in self.track_layers\n",
    "                                                [layer_name].parameters()]\n",
    "        return parameters_dict\n",
    "    \n",
    "    def batch_accuracy(self, outputs, labels):\n",
    "        with torch.no_grad():\n",
    "            return torch.tensor(torch.sum((outputs > 0.5) == labels).item() / len(outputs))\n",
    "    \n",
    "    def _process_batch(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(outputs, labels)\n",
    "        accuracy = self.batch_accuracy(outputs, labels)\n",
    "        return (loss, accuracy)\n",
    "    \n",
    "    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n",
    "        self.train()\n",
    "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n",
    "        optimizer = opt(self.parameters(), lr)\n",
    "        history = []\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accs = []\n",
    "            for batch in dataloader:\n",
    "                loss, acc = self._process_batch(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss.detach()\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "            avg_loss = torch.stack(losses).mean().item()\n",
    "            avg_acc = torch.stack(accs).mean().item()\n",
    "            history.append((avg_loss, avg_acc))\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, dataset, batch_size=64):\n",
    "        self.eval()\n",
    "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n",
    "        losses = []\n",
    "        accs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                loss, acc = self._process_batch(batch)\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "        avg_loss = torch.stack(losses).mean().item()\n",
    "        avg_acc = torch.stack(accs).mean().item()\n",
    "        return (avg_loss, avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_client_id(self):\n",
    "        return self.client_id\n",
    "    \n",
    "    def train(self, parameters_dict, return_model_dict=False):\n",
    "        net = to_device(SimpleFederatedNetwork(), device)\n",
    "        net.apply_parameters(parameters_dict)\n",
    "        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n",
    "        print(self.client_id + ':')\n",
    "        for i, res in enumerate(train_history):\n",
    "            print('Epoch [{}]: Loss = {}, Accuracy = {}'.format(i + 1, round(res[0], 4), round(res[1], 4)))\n",
    "        return net.get_parameters(), net.state_dict() if return_model_dict else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_client = train_dataset_size // num_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [min(i + examples_per_client, train_dataset_size) - i for i in range(0, train_dataset_size, examples_per_client)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define client splits\n",
    "client_datasets = random_split(train_dataset, lengths)\n",
    "clients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate federate network\n",
    "fl = to_device(SimpleFederatedNetwork(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "\n",
    "for i in range(rounds):\n",
    "    print('Start Round {} ...'.format(i + 1))\n",
    "    i_parameters = fl.get_parameters()\n",
    "    i_1_parameters = dict([(layer_name, [0 for param in fl.track_layers[layer_name].parameters()]) for layer_name in i_parameters])\n",
    "    \n",
    "    # Iterate through clients\n",
    "    for j, client in enumerate(clients):\n",
    "        client_parameters, state_dict = client.train(i_parameters, (j == len(clients) - 1))\n",
    "        if j == len(clients) - 1:\n",
    "            fl.load_state_dict(state_dict)\n",
    "            fl.apply_parameters(client_parameters)\n",
    "            train_loss, train_acc = fl.evaluate(train_dataset)\n",
    "            val_loss, val_acc = fl.evaluate(validation_dataset)\n",
    "            print('Results round {}, train_loss = {}, val_loss = {}, val_acc = {}\\n'.format(i + 1, round(train_loss, 4), \n",
    "                    round(val_loss, 4), round(val_acc, 4)))\n",
    "            history.append((train_loss, val_loss))\n",
    "\n",
    "        fraction = client.get_dataset_size() / train_dataset_size\n",
    "        for layer_name in client_parameters:\n",
    "            for j in range(len(client_parameters[layer_name])):\n",
    "                i_1_parameters[layer_name][j] += fraction * client_parameters[layer_name][j]\n",
    "\n",
    "    fl.apply_parameters(i_1_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i + 1 for i in range(len(history))], [history[i][0] for i in range(len(history))], color='r', label='train loss')\n",
    "plt.plot([i + 1 for i in range(len(history))], [history[i][1] for i in range(len(history))], color='b', label='val loss')\n",
    "plt.title('Training history')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 3: Encrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
